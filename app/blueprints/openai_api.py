# openai_api.py

from flask import request, jsonify, current_app, Blueprint, render_template, g
from openai import OpenAI
import tiktoken
import time
import json as pyjson
from flask_security.decorators import auth_required, roles_required
from sentence_processing import convert_template_json_to_text
from logger import logger
from flask_security import current_user
from models import FileMetadata
import re
from app.utils.redis_client import redis_get, redis_set, redis_delete

openai_api_bp = Blueprint("openai_api", __name__)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
def count_tokens(text: str) -> int:
    """
    Counts the number of tokens in the input text for the given OpenAI model.
    
    :param text: The input string.
    :param model: The OpenAI model to use for tokenization ("gpt-4", "gpt-3.5-turbo", etc).
    :return: Number of tokens.
    """
    
    model = current_app.config.get('OPENAI_MODEL')
    
    try:
        encoding = tiktoken.encoding_for_model(model)
    except KeyError:
        # Fallback for unknown models
        encoding = tiktoken.get_encoding("cl100k_base")

    return len(encoding.encode(text))


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI
def _process_openai_request(text: str, assistant_id: str, user_id: int, file_id: str = None, clean_response: bool = True) -> str:
    """
    Internal helper that sends a user message to OpenAI Assistant and returns the assistant's reply.
    Thread and message state is automatically managed via Redis.
    """
    logger.info(f"Processing OpenAI request for assistant ID: {assistant_id} started.")

    thread_key = f"user:{user_id}:assistant:{assistant_id}:thread"
    
    api_key = current_app.config.get("OPENAI_API_KEY")
    client = OpenAI(api_key=api_key)

    thread_id = redis_get(thread_key) 
    logger.info(f"Retrieved thread ID from Redis: {thread_id}")

    if not thread_id:
        logger.info("No thread ID found, creating a new thread.")
        thread = client.beta.threads.create()
        thread_id = thread.id
        redis_set(thread_key, thread_id, ex=3600)  # Store thread ID in Redis for 1 hour
    else:
        logger.info(f"Using existing thread ID: {thread_id}")
        thread = client.beta.threads.retrieve(thread_id)
        
        

    attachments = [{"file_id": file_id, "tools": [{"type": "file_search"}]}] if file_id else None

    message = client.beta.threads.messages.create(
        thread_id=thread_id,
        role="user",
        content=text,
        attachments=attachments
    )
    
    if not message:
        logger.error("Failed to create message in OpenAI thread.")
        
    
    run_args = {
        "thread_id": thread_id,
        "assistant_id": assistant_id,
    }
    
    run = client.beta.threads.runs.create(**run_args)

    while run.status in ["queued", "in_progress"]:
        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
        print(f"Run status: {run.status}")
        time.sleep(1)

    messages = client.beta.threads.messages.list(
        thread_id=thread_id,
        order="asc",
    )

    assistant_reply = ""
    assistant_messages = [msg for msg in messages.data if msg.role == "assistant"]

    if assistant_messages:
        last = assistant_messages[-1]
        for content_block in last.content:
            logger.debug(f"Content block: {content_block}")
            if hasattr(content_block, "text"):
                assistant_reply += content_block.text.value
    if not assistant_reply:
        logger.warning("No assistant reply found in the messages.")
        return "–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–µ –ø–æ–ª—É—á–µ–Ω."
    
    # –û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç —Ü–∏—Ç–∞—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞     
    if clean_response:
        clean_reply = re.sub(r"„Äê.*?„Äë", "", assistant_reply)
        logger.debug(f"Cleaned reply: {clean_reply}")
        return clean_reply
    else:
        logger.debug(f"Raw reply: {assistant_reply}")
        return assistant_reply



# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–±—Ä–æ—Å–∞ —Å–µ—Å—Å–∏–∏ OpenAI
def reset_ai_session(assistant_id: str, user_id: int):
    """
    Clears thread and message tracking for the given assistant from Redis.
    """
    thread_key = f"user:{user_id}:assistant:{assistant_id}:thread"
    redis_delete(thread_key)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API
def gramma_correction_ai(text):
    logger.info("(—Ñ—É–Ω–∫—Ü–∏—è gramma_correction_ai) --------------------------------------")
    logger.info("üöÄ –ù–∞—á–∞—Ç–∞ –ø–æ–ø—ã—Ç–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API.")

    try:
        language = current_app.config.get("APP_LANGUAGE", "ru")
    
        # –ü–æ–ª—É—á–µ–Ω–∏–µ assistant_id –ø–æ modality
        if language == "ru":
            assistant_id = current_app.config.get("OPENAI_ASSISTANT_GRAMMA_CORRECTOR_RU")
        else:
            raise ValueError(f"Unsupported language: {language}")

        if not assistant_id:
            raise ValueError("Assistant ID is not configured.")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
        reset_ai_session(assistant_id, user_id=current_user.id)
        assistant_reply = _process_openai_request(text, assistant_id, user_id=current_user.id)

        logger.info("(—Ñ—É–Ω–∫—Ü–∏—è gramma_correction_ai) ‚úÖ –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        logger.debug(f"(—Ñ—É–Ω–∫—Ü–∏—è gramma_correction_ai) –û—Ç–≤–µ—Ç: {assistant_reply}")
        logger.info("---------------------------------------------------")
        return assistant_reply

    except Exception as e:
        logger.exception(f"(—Ñ—É–Ω–∫—Ü–∏—è gramma_correction_ai) ‚ùå Unexpected error: {str(e)}")
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ò–ò: error {e}")
  
  
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI. –ò—Å–ø–æ–ª—å–∑—É—é –≤ analyze_dinamics –≤ working_with_reports.py
def clean_raw_text(raw_text: str, user_id: int, max_attempts: int = 2) -> str:
    logger.info("(–§—É–Ω–∫—Ü–∏—è clean_raw_text) --------------------------------------")
    logger.info("[clean_raw_text] üöÄ –ù–∞—á–∞—Ç–∞ –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API.")
    logger.info("---------------------------------------------------")
    
    cleaner_assistant_id = current_app.config.get("OPENAI_ASSISTANT_TEXT_CLEANER")
    if not cleaner_assistant_id:
        logger.error("[clean_raw_text] ‚ùå Assistant ID for text cleaner is not configured.")
        raise ValueError("Assistant ID for text cleaner is not configured.")
    
    for attempt in range(max_attempts):
        try:
            cleaned = _process_openai_request(
                text=raw_text,
                assistant_id=cleaner_assistant_id,
                user_id=user_id,
                file_id=None,
                clean_response=False
            )
            if cleaned:
                logger.info(f"[clean_raw_text] ‚úÖ –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —É—Å–ø–µ—à–Ω–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}.")
                logger.info(f"[clean_raw_text] –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞: {cleaned}")
                logger.info("---------------------------------------------------")
                return cleaned
        except Exception as e:
            logger.warning(f"[clean_raw_text] ‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
        finally:
            reset_ai_session(cleaner_assistant_id, user_id=user_id)

    logger.warning("[clean_raw_text] ‚ö†Ô∏è –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞—é –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç")
    logger.info("---------------------------------------------------")
    return raw_text



# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–µ—Ä–≤–æ–≥–æ –≤–∑–≥–ª—è–¥–∞. –ò—Å–ø–æ–ª—å–∑—É—é –≤ analyze_dinamics –≤ working_with_reports.py
def run_first_look_assistant(cleaned_text: str, template_text: list, user_id: int, max_attempts: int = 2) -> str:
    logger.info("(–§—É–Ω–∫—Ü–∏—è run_first_look_assistant) --------------------------------------")
    logger.info("[run_first_look_assistant] üöÄ –ù–∞—á–∞—Ç–∞ –ø–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ –≤–∑–≥–ª—è–¥–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API.")
    logger.info("---------------------------------------------------")
    
    converted_template_text = convert_template_json_to_text(template_text)
    if not converted_template_text:
        logger.error("[run_first_look_assistant] ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —à–∞–±–ª–æ–Ω –≤ —Ç–µ–∫—Å—Ç.")
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —à–∞–±–ª–æ–Ω –≤ —Ç–µ–∫—Å—Ç.")

    prompt = f"""TEMPLATE REPORT:
                {converted_template_text}
                RAW REPORT:
                {cleaned_text}
                """
                
    first_look_assistant_id = current_app.config.get("OPENAI_ASSISTANT_FIRST_LOOK_RADIOLOGIST")
    if not first_look_assistant_id:
        logger.error("[run_first_look_assistant] ‚ùå Assistant ID for first look is not configured.")
        raise ValueError("Assistant ID for first look is not configured.")

    for attempt in range(max_attempts):
        try:
            result = _process_openai_request(
                text=prompt,
                assistant_id=first_look_assistant_id,
                user_id=user_id,
                file_id=None,
                clean_response=False
            )
            if result:
                logger.info(f"[run_first_look_assistant] ‚úÖ –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –≤–∑–≥–ª—è–¥–∞ —É—Å–ø–µ—à–Ω–æ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}.")
                logger.info(f"[run_first_look_assistant] –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {result}")
                logger.info("---------------------------------------------------")
                return result
        except Exception as e:
            logger.warning(f"[run_first_look_assistant] ‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
        finally:
            reset_ai_session(first_look_assistant_id, user_id=user_id)

    logger.error("[run_first_look_assistant] ‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ –≤–∑–≥–ª—è–¥–∞ –Ω–µ —É–¥–∞–ª–∏—Å—å")
    logger.info("---------------------------------------------------")
    raise ValueError("–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ –≤–∑–≥–ª—è–¥–∞ –Ω–µ —É–¥–∞–ª–∏—Å—å.")


# –û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API
def structure_report_text(template_text: list, report_text: str, user_id: int, max_attempts: int = 2) -> list:
    logger.info("(–§—É–Ω–∫—Ü–∏—è structure_report_text) --------------------------------------")
    logger.info("[structure_report_text] üöÄ –ù–∞—á–∞—Ç–∞ –ø–æ–ø—ã—Ç–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API.")
    logger.info("---------------------------------------------------")

    prompt = f"""REPORT TEMPLATE:
                {template_text}
                ORIGINAL MEDICAL REPORT TEXT:
                {report_text}
                """

    structurer_assistant_id = current_app.config.get("OPENAI_ASSISTANT_DYNAMIC_STRUCTURER")
    if not structurer_assistant_id:
        logger.error("[structure_report_text] ‚ùå Assistant ID for structurer is not configured.")
        raise ValueError("Assistant ID for structurer is not configured.")

    for attempt in range(max_attempts):
        try:
            result_text = _process_openai_request(
                text=prompt,
                assistant_id=structurer_assistant_id,
                user_id=user_id,
                file_id=None,
                clean_response=False,
            )
            if not result_text:
                logger.warning(f"[structure_report_text] ‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.")
                continue
            logger.info(f"[structure_report_text] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}.")
            
            try:
                # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ—Ç–≤–µ—Ç –∫–∞–∫ JSON
                parsed = pyjson.loads(result_text)
            except pyjson.JSONDecodeError:
                logger.warning(f"[structure_report_text] ‚ùå –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º JSON.")
                raise ValueError("–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º JSON. –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å.")
            
            if isinstance(parsed, dict):
                logger.info("[structure_report_text] ‚úÖ –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º. –î–æ—Å—Ç–∞—é report.")
                para_list = parsed.get("report", [])
                logger.info(f"[structure_report_text] ‚úÖ –£–¥–∞–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç—å report. –¢–µ–ø–µ—Ä—å report —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —Å–æ–¥–µ—Ä–∂–∞—â–∏–π: {len(para_list)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤.")
            elif isinstance(parsed, list):
                logger.info(f"[structure_report_text] üôå –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —è–≤–ª—è–µ—Ç—Å—è —Å–ø–∏—Å–∫–æ–º —Å {len(parsed)} —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏. –ü—Ä–æ–±—É—é –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –µ–≥–æ")
                para_list = parsed
            else:
                logger.error("[structure_report_text] ‚ùå –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –Ω–∏ —Å–ø–∏—Å–∫–æ–º, –Ω–∏ —Å–ª–æ–≤–∞—Ä–µ–º.")
                raise ValueError("–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –Ω–∏ —Å–ø–∏—Å–∫–æ–º, –Ω–∏ —Å–ª–æ–≤–∞—Ä–µ–º.")
            
            if para_list:
                logger.info(f"[structure_report_text] ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ —É—Å–ø–µ—à–Ω–æ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}.")
                logger.info(f"[structure_report_text] –û—Ç—á–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—é: {para_list}")
                logger.info("---------------------------------------------------")
                return para_list
        except Exception as e:
            logger.warning(f"[structure_report_text] ‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
        finally:
            reset_ai_session(structurer_assistant_id, user_id=user_id)

    logger.error("[structure_report_text] ‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞ –Ω–µ —É–¥–∞–ª–∏—Å—å")
    logger.info("---------------------------------------------------")
    raise ValueError("–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞ –Ω–µ —É–¥–∞–ª–∏—Å—å.")
    
    
  
  
  
# Routs

@openai_api_bp.route("/start_openai_api", methods=["POST", "GET"])
@auth_required()
def start_openai_api():
    return render_template(
        "openai_api.html",
        title="GPT",
    )


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –≤–µ–¥–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞ GENERAL
@openai_api_bp.route("/generate_general", methods=['POST'])
@auth_required()
def generate_general():
    logger.info("(–ú–∞—Ä—à—Ä—É—Ç generate_general) --------------------------------------")
    logger.info("üöÄ –ù–∞—á–∞—Ç–∞ –ø–æ–ø—ã—Ç–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API.")
    
    data = request.get_json()
    text = data.get("text")
    logger.debug(f"–ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ: {data}")
    new_conversation = data.get("new_conversation", True)
    ai_assistant = current_app.config.get("OPENAI_ASSISTANT_GENERAL")
    tokens = count_tokens(text)
    if not text:
        return jsonify({"status": "error", "message": "Your request is empty"}), 400
    if not ai_assistant:
        return jsonify({"status": "error", "message": "Assistant ID is not configured."}), 500
    if tokens > 4000:
        return jsonify({"status": "error", "message": f"–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π - { tokens } —Ç–æ–∫–µ–Ω–æ–≤, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –µ–≥–æ."}), 400
    
    if new_conversation:
        reset_ai_session(ai_assistant, user_id=current_user.id)
    message = _process_openai_request(text, ai_assistant, user_id=current_user.id)
    if message:
        logger.info("‚úÖ –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        logger.debug(f"–û—Ç–≤–µ—Ç: {message}")
        logger.info("---------------------------------------------------")
        return jsonify({"status": "success", "data": message}), 200
    else:
        logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.")
        logger.info("---------------------------------------------------")
        return jsonify({"status": "error", "message": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."}), 500



# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –≤–µ–¥–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞ REDACTOR
@openai_api_bp.route("/generate_redactor", methods=['POST'])
@auth_required()
def generate_redactor():
    logger.info("(–ú–∞—Ä—à—Ä—É—Ç generate_redactor) --------------------------------------")
    logger.info("üöÄ –ù–∞—á–∞—Ç–∞ –ø–æ–ø—ã—Ç–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API.")
    data = request.get_json()
    text = data.get("text")
    logger.debug(f"–ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ: {data}")
    ai_assistant = current_app.config.get("OPENAI_ASSISTANT_REDACTOR")
    if not text:
        return jsonify({"status": "error", "message": "Your request is empty"}), 400
    if not ai_assistant:
        return jsonify({"status": "error", "message": "Assistant ID is not configured."}), 500
    try:
        reset_ai_session(ai_assistant, user_id=current_user.id)
        message = _process_openai_request(text, ai_assistant, user_id=current_user.id)
        if not message:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.")
            logger.info("---------------------------------------------------")
            return jsonify({"status": "error", "message": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."}), 500
        logger.info("‚úÖ –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        logger.info(f"–û—Ç–≤–µ—Ç: {message}")
        logger.info("---------------------------------------------------")
        return jsonify({"status": "success", "data": message}), 200
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {str(e)}")
        logger.info("---------------------------------------------------")
        return jsonify({"status": "error", "message": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."}), 500
     
    

@openai_api_bp.route("/generate_impression", methods=['POST'])
@auth_required()
def generate_impression():
    logger.info("(–ú–∞—Ä—à—Ä—É—Ç generate_impression) --------------------------------------")
    logger.info("üöÄ –ù–∞—á–∞—Ç–∞ –ø–æ–ø—ã—Ç–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API.")

    user_id = current_user.id if current_user.is_authenticated else None
    
    try:
        data = request.get_json()
        text = data.get("text")
        modality = data.get("modality")
        logger.debug(f"–ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ: {data}")

        if not text:
            return jsonify({"status": "error", "message": "Your request is empty"}), 400
        if not modality:
            return jsonify({"status": "error", "message": "Modality is missing"}), 400

        file_key = f"user:{user_id}:impression_file_id:{modality}"
        file_id = redis_get(file_key)
        if not file_id:
            logger.error({f"No impression file ID found in Redis for modality: {modality}"}), 400

        # –ü–æ–ª—É—á–µ–Ω–∏–µ assistant_id –ø–æ modality
        if modality == "MRI":
            assistant_id = current_app.config.get("OPENAI_ASSISTANT_MRI")
        elif modality == "CT":
            assistant_id = current_app.config.get("OPENAI_ASSISTANT_CT")
        elif modality == "XRAY":
            assistant_id = current_app.config.get("OPENAI_ASSISTANT_XRAY")
        else:
            return jsonify({"status": "error", "message": f"Unknown modality: {modality}"}), 400

        if not assistant_id:
            return jsonify({"status": "error", "message": "Assistant ID is not configured."}), 500

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
        reset_ai_session(assistant_id, user_id=user_id)
        assistant_reply = _process_openai_request(text, assistant_id, user_id=user_id, file_id=file_id)

        logger.info("‚úÖ –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        logger.debug(f"–û—Ç–≤–µ—Ç: {assistant_reply}")
        logger.info("---------------------------------------------------")
        return jsonify({"status": "success", "data": assistant_reply}), 200

    except Exception as e:
        logger.exception(f"‚ùå Unexpected error: {str(e)}")
        return jsonify({"status": "error", "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ò–ò: error {e}" }), 500


# –ú–∞—Ä—à—Ä—É—Ç –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –∏—Å–ø–ª—å–∑—É—é –≤ new_report_creation (–º–æ–∂–Ω–æ —Ç–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ analyze_dinamics –µ—Å–ª–∏ —Ä–∞–∑–±–∏—Ç—å –µ–µ –Ω–∞ —á–∞—Å—Ç–∏)
@openai_api_bp.route("/clean_raw_text", methods=['POST'])
@auth_required()
def clean_raw_text_route():
    logger.info("(–ú–∞—Ä—à—Ä—É—Ç clean_raw_text_route) --------------------------------------")
    logger.info(f"(–ú–∞—Ä—à—Ä—É—Ç clean_raw_text_route) üöÄ –ù–∞—á–∞—Ç–∞ –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API.")
    data = request.get_json()
    raw_text = data.get("raw_text", "")
    if not raw_text.strip():
        logger.error(f"(–ú–∞—Ä—à—Ä—É—Ç clean_raw_text_route) ‚ùå –ù–µ –ø–µ—Ä–µ–¥–∞–Ω —Ç–µ–∫—Å—Ç –¥–ª—è –æ—á–∏—Å—Ç–∫–∏")
        return jsonify({"status": "error", "message": "–ù–µ –ø–µ—Ä–µ–¥–∞–Ω —Ç–µ–∫—Å—Ç"}), 400
    try:
        cleaned = clean_raw_text(raw_text, user_id=current_user.id)
        logger.info(f"(–ú–∞—Ä—à—Ä—É—Ç clean_raw_text_route) ‚úÖ –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —É—Å–ø–µ—à–Ω–∞")
        logger.info(f"(–ú–∞—Ä—à—Ä—É—Ç clean_raw_text_route) ------------------------------------------")
        return jsonify({"status": "success", "message": "–¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω", "data": cleaned}), 200
    except Exception as e:
        logger.error(f"(–ú–∞—Ä—à—Ä—É—Ç clean_raw_text_route) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞: {str(e)}")
        logger.info("---------------------------------------------------")
        return jsonify({"status": "error", "message": str(e)}), 500



@openai_api_bp.route("/ocr_extract_text", methods=["POST"])
@auth_required()
def ocr_extract_text():
    logger.info(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ------------------------------------")
    logger.info(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
    try:
        file = request.files.get("file")
        if not file:
            logger.error(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return jsonify({"status": "error", "message": "No file uploaded"}), 400
        from file_processing import extract_text_from_uploaded_file
        text, error = extract_text_from_uploaded_file(file)
        if error:
            # –ï—Å–ª–∏ pdf ‚Äî –æ—Ç–¥–∞—Ç—å –∫–æ–¥ 200, –Ω–æ —Å–æ–æ–±—â–∏—Ç—å —á—Ç–æ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
            if "PDF files are not supported" in error:
                logger.info(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) üìÑ PDF —Ñ–∞–π–ª –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
                return jsonify({"status": "success", "text": "", "message": error}), 200
            logger.error(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {error}")
            return jsonify({"status": "error", "message": error}), 400
        logger.info(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ‚úÖ –¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω")
        return jsonify({"status": "success", "text": text}), 200
    except Exception as e:
        logger.error(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500
    
    
    
    