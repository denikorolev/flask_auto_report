#working_with_reports.py

from flask import Blueprint, render_template, request, jsonify, current_app, session
from flask_security import current_user
from app.models.models import db, Report, KeyWord, TailSentence, BodySentence, ReportTextSnapshot
from app.utils.sentence_processing import group_keywords, split_sentences_if_needed, clean_and_normalize_text, compare_sentences_by_paragraph, preprocess_sentence, split_report_structure_for_ai, replace_head_sentences_with_fuzzy_check, merge_ai_response_into_skeleton
from app.utils.common import ensure_list
from app.utils.logger import logger
from flask_security.decorators import auth_required
from tasks.celery_tasks import async_analyze_dynamics



working_with_reports_bp = Blueprint('working_with_reports', __name__)

# Functions

# Routes

@working_with_reports_bp.route("/choosing_report", methods=['POST', 'GET'])
@auth_required()
def choosing_report(): 
    logger.info(f"(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ------------------------------------")
    logger.info(f"(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞")
    profile_id = session.get("profile_id")

    if request.method == "POST":
        logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) –ü–æ–ª—É—á–µ–Ω POST-–∑–∞–ø—Ä–æ—Å –Ω–∞ –≤—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞.")
        if request.is_json:
            data = request.get_json()
            logger.info(f"(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {data}")
            rep_area = data.get("report_area")
            reports = Report.find_by_category_2(rep_area, profile_id) if rep_area else []
            if not reports:
                logger.error("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —à–∞–±–ª–æ–Ω–æ–≤ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞")
                return jsonify({"status": "error", "message": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —à–∞–±–ª–æ–Ω–æ–≤ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞"}), 404
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
            logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ------------------------------------")
            logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è—é –¥–∞–Ω–Ω—ã–µ –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —à–∞–±–ª–æ–Ω–∞—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
            return jsonify({
                "status": "success",
                "reports": [
                    {"id": report.id, "report_name": report.report_name}
                    for report in reports
                ]
            })
    logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) –ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã.")
    return render_template(
        "choose_report.html",
        title="–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞",
    )


@working_with_reports_bp.route("/working_with_reports", methods=['GET'])
@auth_required()
def working_with_reports():
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ------------------------------------") 
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
    current_report_id = int(request.args.get("reportId"))
    profile_id = session.get("profile_id")
    
    if not current_report_id:
    
        logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
        return render_template("errors/error.html", message="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–¥—Ö–æ–¥—è—â–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª–µ –¥–ª—è —Ä–∞–±–æ—Ç—ã")
    try:
        report_data, paragraphs_data = Report.get_report_data(current_report_id)
        if report_data is None or paragraphs_data is None:
            logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ú–µ—Ç–æ–¥ get_report_data –≤–µ—Ä–Ω—É–ª None")
            return render_template("errors/error.html", message="–ú–µ—Ç–æ–¥ get_report_data –≤–µ—Ä–Ω—É–ª None")
    except Exception as e:
        logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {e}")
        return render_template("errors/error.html", message=f"–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {e}")
    
    # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    try:
        key_words_obj = KeyWord.get_keywords_for_report(profile_id, current_report_id)
        key_words_groups = group_keywords(key_words_obj)
    except Exception as e:
        logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
        return render_template("errors/error.html", message=f"–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–æ–ª–æ—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
   
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ------------------------------------")
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚úÖ –î–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏ –µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã. –ó–∞–≥—Ä—É–∂–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É")
    return render_template(
        "working_with_report.html", 
        title=report_data["report_name"],
        report_data=report_data,
        paragraphs_data=paragraphs_data,
        key_words_groups=key_words_groups,
    )


    

@working_with_reports_bp.route("/save_modified_sentences", methods=["POST"])
@auth_required()
def save_modified_sentences():
    """
    Processes and saves new or modified sentences to the database.
    Handles splitting of multi-sentence inputs and normalizes valid sentences.
    Keeps track of saved, skipped, and missed sentences.
    """
    
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ------------------------------------")
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        data = request.get_json()
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {data}")

        report_id = int(data.get("report_id"))
        sentences = ensure_list(data.get("sentences"))
        user_id = current_user.id
        report_global_modality_id = Report.get_by_id(report_id).global_category_id
        profile_id = session.get("profile_id")
        language = session.get("lang", "default_language")
        
        if not sentences or not report_id:
            logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–ª–∏ id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
            return jsonify({"status": "error", "message": "–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–ª–∏ id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞"}), 400
        
        processed_sentences = []  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, 
        #–æ—Ç–ø—Ä–∞–≤–ª—é –∏—Ö –ø–æ—Ç–æ–º –Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤ —Ñ—É–Ω–∫—Ü–∏—é compare_sentences_by_paragraph
        missed_count = 0  # –°—á—ë—Ç—á–∏–∫ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        

        for sentence_data in sentences:
            head_sentence_id = sentence_data.get("head_sentence_id", None)
            paragraph_id = sentence_data.get("paragraph_id")
            nativ_text = sentence_data.get("text")
            sentence_type = sentence_data.get("type")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
            if not paragraph_id or not nativ_text.strip():
                missed_count += 1
                logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –¥–∞–Ω–Ω—ã–µ –±–µ–∑ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç: {sentence_data}")
                continue  
            
            before_split_text = preprocess_sentence(nativ_text)
            
            if not before_split_text.strip():
                missed_count += 1
                continue  
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
            unsplited_sentences, splited_sentences = split_sentences_if_needed(before_split_text, language)

            if splited_sentences:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª—É—á–∞–∏ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º
                for idx, splited_sentence in enumerate(splited_sentences):
                    new_sentence_type = sentence_type
                    if splited_sentence.strip() == "":
                        missed_count += 1
                        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –ø—É—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {splited_sentence}")
                        continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                    if sentence_type == "body":
                        new_sentence_type = "body" if idx == 0 else "tail"
                    else:
                        new_sentence_type = "tail"
                    processed_sentences.append({
                        "paragraph_id": paragraph_id,
                        "head_sentence_id": head_sentence_id,
                        "sentence_type": new_sentence_type,
                        "text": splited_sentence.strip()
                    })
            else:
                for unsplited_sentence in unsplited_sentences:
                    if unsplited_sentence.strip() == "":
                        missed_count += 1
                        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –ø—É—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {unsplited_sentence}")
                        continue
                    processed_sentences.append({
                        "paragraph_id": paragraph_id,
                        "head_sentence_id": head_sentence_id,
                        "sentence_type": "body" if sentence_type == "body" else "tail",
                        "text": unsplited_sentence.strip()
                    })

        # –¢–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞–µ–º —Å —É–∂–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –≤ processed_sentences
        
        # –°–Ω–∞—á–∞–ª–∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏—Ö —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        comparsion_result = compare_sentences_by_paragraph(
                                                        processed_sentences,
                                                        report_id,
                                                        profile_id=profile_id)

        new_sentences = comparsion_result["unique"]
        duplicates = comparsion_result["duplicates"]
        errors_count = comparsion_result["errors_count"]
        
        missed_count = 0  # –°—á—ë—Ç—á–∏–∫ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        saved_count = 0  # –°—á—ë—Ç—á–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        saved_sentences = []  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –æ—Ç—á–µ—Ç

        for sentence in new_sentences:
            processed_paragraph_id = sentence["paragraph_id"]
            head_sent_id = sentence["head_sentence_id"]
            new_sentence_text = clean_and_normalize_text(sentence["text"], profile_id)
            sentence_type = sentence["sentence_type"]
            related_id = processed_paragraph_id if sentence_type == "tail" else head_sent_id
            try:
                if sentence_type == "tail":
                   new_sentence, sent_group = TailSentence.create(
                        sentence=new_sentence_text,
                        related_id=related_id,
                        user_id=user_id,
                        report_global_modality_id=report_global_modality_id,
                        comment="Added automatically"
                    )
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –≤ –∫–∞—á–µ—Å—Ç–≤–µ body_sentence 
                # –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –≥–ª–∞–≤–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                else:
                    if sentence["head_sentence_id"]:
                        new_sentence, sent_group = BodySentence.create(
                        sentence=new_sentence_text,
                        related_id=related_id,
                        user_id=user_id,
                        report_global_modality_id=report_global_modality_id,
                        comment="Added automatically",
                        )
                    else:
                        logger.warning(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω head_sentence_id –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {new_sentence_text}. –ü—Ä–æ–ø—É—Å–∫–∞—é –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ")
                        missed_count += 1   
                        continue
                saved_count += 1
                saved_sentences.append({"id": new_sentence.id, "related_id": related_id, "sentence_type": sentence_type, "text": new_sentence_text})
            except Exception as e:
                logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ùå –ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è ({new_sentence_text}) –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}. –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ —Å—á—ë—Ç—á–∏–∫")
                missed_count += 1

        sentences_adding_report = {
            "message": f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {len(processed_sentences)}.",
            "saved_count": saved_count,
            "skipped_count": len(processed_sentences) - saved_count,
            "missed_count": missed_count,
            "duplicates_count": len(duplicates),
            "errors_count": errors_count,
            "saved_sentences": saved_sentences,
            "duplicates": duplicates
        }

        rendered_html = render_template(
            "sentences_adding_report_snippet.html", 
            **sentences_adding_report)
        
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(processed_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.")
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ------------------------------------")
        return jsonify({
            "status": "success",
            "message": f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(processed_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.",
            "html": rendered_html
        }), 200

    except Exception as e:
        logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ùå –ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")
        return jsonify({"status": "error", "message": f"–ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"}), 500




@working_with_reports_bp.route("/save_report_snapshot", methods=["POST"])
@auth_required()
def save_report_snapshot():
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ------------------------------------")
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
    try:
        data = request.get_json()
        if not data:
            logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON")
            return jsonify({"status": "error", "message": "No JSON data received"}), 400
        report_id = data.get("report_id")
        text = data.get("text")
        if not report_id or not text:
            logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞ –∫–æ–ø–∏–∏")
            return jsonify({"status": "error", "message": "Missing required information."}), 400
        
        user_id = current_user.id
        
    except Exception as e:
        logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return jsonify({"status": "error", "message": f"Error processing request: {e}"}), 500

    try:
        ReportTextSnapshot.create(report_id, user_id, text)
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚úÖ –ö–æ–ø–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        return jsonify({"status": "success", "message": "Report snapshot saved"}), 200
    except Exception as e:
        logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–ø–∏—é –ø—Ä–æ—Ç–æ–∫–æ–ª–∞: {e}")
        return jsonify({"status": "error", "message": f"Failed to save report snapshot: {e}"}), 500
    



# editing_report.py
@working_with_reports_bp.route("/increase_sentence_weight", methods=["POST"])
@auth_required()
def increase_sentence_weight():
    logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ------------------------------------")
    logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
    data = request.get_json()
    sentence_id = data.get("sentence_id")
    group_id = data.get("group_id")
    sentence_type = data.get("sentence_type")
    
    logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {data}")

    if not sentence_id or not group_id or sentence_type not in ["body", "tail"]:
        logger.error(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
        return jsonify({"status": "error", "message": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö"}), 400

    try:
        if sentence_type == "body":
            BodySentence.increase_weight(sentence_id, group_id)
        else:
            TailSentence.increase_weight(sentence_id, group_id)
        logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ‚úÖ –í–µ—Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ —É–≤–µ–ª–∏—á–µ–Ω")
        return jsonify({"status": "success", "message": "–í–µ—Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —É–≤–µ–ª–∏—á–µ–Ω"}), 200
    except Exception as e:
        logger.error(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤–µ—Å–∞: {e}")
        return jsonify({"status": "error", "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤–µ—Å–∞: {e}"}), 500
    
     

# –ú–∞—Ä—à—Ä—É—Ç –¥–ª—è –ø–µ—Ä–µ–¥–µ–ª—ã–≤–∞–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ –æ–±—Ä–∞–∑—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —à–∞–±–ª–æ–Ω–∞
@working_with_reports_bp.route("/analyze_dynamics", methods=["POST"])
@auth_required()
def analyze_dynamics():
    logger.info(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ---------------------------------------------")
    logger.info(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) üöÄ –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏ –ø–æ —Ç–µ–∫—Å—Ç—É –∏ —à–∞–±–ª–æ–Ω—É –æ—Ç—á–µ—Ç–∞")
    logger.info("----------------------------------------------------------------")
    
    data = request.get_json()
    origin_text = data.get("origin_text", "").strip()
    report_id = data.get("report_id")
    user_id = current_user.id

    if not origin_text or not report_id:
        logger.error("–ù–µ –ø–µ—Ä–µ–¥–∞–Ω —Ç–µ–∫—Å—Ç –∏–ª–∏ report_id")
        return jsonify({"status": "error", "message": "–ù–µ –ø–µ—Ä–µ–¥–∞–Ω —Ç–µ–∫—Å—Ç –∏–ª–∏ report_id"}), 400

    report_data, sorted_parag = Report.get_report_data(report_id)
    if not report_data:
        logger.error("–®–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return jsonify({"status": "error", "message": "–®–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω"}), 404

    skeleton, template_text = split_report_structure_for_ai(sorted_parag)
    if not template_text or not skeleton:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —à–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞")
        return jsonify({"status": "error", "message": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —à–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞"}), 500

    logger.info(f"‚úÖ –®–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω. –ü–æ–ª—É—á–µ–Ω—ã json —Å—Ç—Ä—É–∫—Ç—É—Ä—ã skeleton –∏ template_text")
    
    try:
        first_look_assistant_id = current_app.config.get("OPENAI_ASSISTANT_FIRST_LOOK_RADIOLOGIST")
        structure_assistant_id = current_app.config.get("OPENAI_ASSISTANT_DYNAMIC_STRUCTURER")
        task = async_analyze_dynamics.delay(origin_text, template_text, user_id, skeleton, report_id, first_look_assistant_id, structure_assistant_id)
    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å celery –∑–∞–¥–∞—á—É async_analyze_dynamics: {e}")
        return jsonify({
            "status": "error",
            "message": f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏: {str(e)}"
        }), 500

    return jsonify({
        "status": "success",
        "message": "–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏ –∑–∞–ø—É—â–µ–Ω",
        "task_id": task.id,
    }), 200

       
        

# –ú–∞—Ä—à—Ä—É—Ç –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —ç—Ç–∞–ø–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —à–∞–±–ª–æ–Ω–∞ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º
@working_with_reports_bp.route("/analyze_dynamics_finalize", methods=["POST"])
def analyze_dynamics_finalize():
    logger.info(f"(–§–∏–Ω–∞–ª—å–Ω—ã–π —ç—Ç–∞–ø –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏) ------------------------------------")
    logger.info(f"(–§–∏–Ω–∞–ª—å–Ω—ã–π —ç—Ç–∞–ø –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏) üöÄ –ù–∞—á–∏–Ω–∞—é —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —ç—Ç–∞–ø –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏")
    
    try:
        data = request.get_json()
        result = data.get("result")  # —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã celery –∑–∞–¥–∞—á–∏
        report_id = data.get("report_id")
        skeleton = data.get("skeleton")
        profile_id = session.get("profile_id")

        if not result or not report_id:
            return jsonify({"status": "error", "message": "Missing required data"}), 400

        report_data, sorted_parag = Report.get_report_data(report_id)
        
        try:
            key_words_obj = KeyWord.get_keywords_for_report(profile_id, report_id)
            key_words_groups = group_keywords(key_words_obj)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {e}")
            key_words_groups = []
        

        merged_parag, misc_sentences = merge_ai_response_into_skeleton(skeleton, result)
        initial_report = replace_head_sentences_with_fuzzy_check(sorted_parag, merged_parag)

        new_html = render_template(
            "working_with_report.html",
            title=report_data["report_name"],
            report_data=report_data,
            paragraphs_data=initial_report,
            key_words_groups=key_words_groups,
        )
        return jsonify({
            "status": "success",
            "message": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç—á–µ—Ç–∞ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞",
            "report_data": report_data,
            "paragraphs_data": initial_report,
            "key_words_groups": key_words_groups,
            "html": new_html,
            "misc_sentences": misc_sentences,
        }), 200
    except Exception as e:
        logger.error(f"(–§–∏–Ω–∞–ª—å–Ω—ã–π —ç—Ç–∞–ø –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —ç—Ç–∞–ø–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏: {e}")
        return jsonify({"status": "error", "message": f"–û—à–∏–±–∫–∞ –∑–∞–º–µ–Ω—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {e}"}), 500






