# ..utils/ai_processing.py

from flask import current_app
from openai import OpenAI
import tiktoken
import time
import json as pyjson
import re
from flask_security import current_user
from app.utils.logger import logger
from app.utils.redis_client import redis_get, redis_set, redis_delete
from app.utils.sentence_processing import convert_template_json_to_text




# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
def count_tokens(text: str, model: str) -> int:
    """
    Counts the number of tokens in the input text for the given OpenAI model.
    
    :param text: The input string.
    :param model: The OpenAI model to use for tokenization ("gpt-4", "gpt-3.5-turbo", etc).
    :return: Number of tokens.
    """
    from tasks.extensions import celery
    
    try:
        encoding = tiktoken.encoding_for_model(model)
    except KeyError:
        # Fallback for unknown models
        encoding = tiktoken.get_encoding("cl100k_base")

    return len(encoding.encode(text))


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI
def _process_openai_request(text: str, assistant_id: str, user_id: int, file_id: str = None, clean_response: bool = True) -> str:
    """
    Internal helper that sends a user message to OpenAI Assistant and returns the assistant's reply.
    Thread and message state is automatically managed via Redis.
    """
    logger.info(f"(—Ñ—É–Ω–∫—Ü–∏—è _process_openai_request) üöÄ Processing OpenAI request started.")

    thread_key = f"user:{user_id}:assistant:{assistant_id}:thread"
    
    api_key = current_app.config.get("OPENAI_API_KEY", None)
    if not api_key:
        logger.warning(f"(—Ñ—É–Ω–∫—Ü–∏—è _process_openai_request) ‚ö†Ô∏è OpenAI API key not found in Flask config, trying to get it from Celery config.")
        from tasks.extensions import celery
        api_key = celery.conf.get("OPENAI_API_KEY", None)
        if not api_key:
            logger.error(f"(—Ñ—É–Ω–∫—Ü–∏—è _process_openai_request) OpenAI API key is not configured.")
            raise ValueError("OpenAI API key is not configured.")
    client = OpenAI(api_key=api_key)

    thread_id = redis_get(thread_key) 
    logger.info(f"(—Ñ—É–Ω–∫—Ü–∏—è _process_openai_request) Retrieved thread ID from Redis: {thread_id}")

    if not thread_id:
        logger.info(f"(—Ñ—É–Ω–∫—Ü–∏—è _process_openai_request) No thread ID found, creating a new thread.")
        thread = client.beta.threads.create()
        thread_id = thread.id
        redis_set(thread_key, thread_id, ex=3600)  # Store thread ID in Redis for 1 hour
    else:
        logger.info(f"(—Ñ—É–Ω–∫—Ü–∏—è _process_openai_request) Using existing thread ID: {thread_id}")
        thread = client.beta.threads.retrieve(thread_id)
        
        

    attachments = [{"file_id": file_id, "tools": [{"type": "file_search"}]}] if file_id else None

    message = client.beta.threads.messages.create(
        thread_id=thread_id,
        role="user",
        content=text,
        attachments=attachments
    )
    
    if not message:
        logger.error(f"(—Ñ—É–Ω–∫—Ü–∏—è _process_openai_request) Failed to create message in OpenAI thread.")
        
    
    run_args = {
        "thread_id": thread_id,
        "assistant_id": assistant_id,
    }
    
    run = client.beta.threads.runs.create(**run_args)

    while run.status in ["queued", "in_progress"]:
        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
        time.sleep(1.5)
        
    messages = client.beta.threads.messages.list(
        thread_id=thread_id,
        order="asc",
    )

    assistant_reply = ""
    assistant_messages = [msg for msg in messages.data if msg.role == "assistant"]

    if assistant_messages:
        last = assistant_messages[-1]
        for content_block in last.content:
            logger.debug(f"(—Ñ—É–Ω–∫—Ü–∏—è _process_openai_request) Content block: {content_block}")
            if hasattr(content_block, "text"):
                assistant_reply += content_block.text.value
    if not assistant_reply:
        logger.warning(f"(—Ñ—É–Ω–∫—Ü–∏—è _process_openai_request) No assistant reply found in the messages.")
        return "–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–µ –ø–æ–ª—É—á–µ–Ω."
    
    # –û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç —Ü–∏—Ç–∞—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞     
    if clean_response:
        clean_reply = re.sub(r"„Äê.*?„Äë", "", assistant_reply)
        logger.debug(f"(—Ñ—É–Ω–∫—Ü–∏—è _process_openai_request) Cleaned reply: {clean_reply}")
        return clean_reply
    else:
        logger.debug(f"(—Ñ—É–Ω–∫—Ü–∏—è _process_openai_request) Raw reply: {assistant_reply}")
        return assistant_reply



# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–±—Ä–æ—Å–∞ —Å–µ—Å—Å–∏–∏ OpenAI
def reset_ai_session(assistant_id: str, user_id: int):
    """
    Clears thread and message tracking for the given assistant from Redis.
    """
    try:
        thread_key = f"user:{user_id}:assistant:{assistant_id}:thread"
        redis_delete(thread_key)
        logger.info(f"(—Ñ—É–Ω–∫—Ü–∏—è reset_ai_session) ‚úÖ –°–µ—Å—Å–∏—è OpenAI –¥–ª—è assistant_id {assistant_id} –∏ user_id {user_id} —É—Å–ø–µ—à–Ω–æ —Å–±—Ä–æ—à–µ–Ω–∞.")
    except Exception as e:
        logger.error(f"(—Ñ—É–Ω–∫—Ü–∏—è reset_ai_session) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±—Ä–æ—Å–µ —Å–µ—Å—Å–∏–∏ OpenAI: {str(e)}")
        


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API
def gramma_correction_ai(text: str, language: str, assistant_id: str) -> str:
    logger.info("(—Ñ—É–Ω–∫—Ü–∏—è gramma_correction_ai) --------------------------------------")
    logger.info("üöÄ –ù–∞—á–∞—Ç–∞ –ø–æ–ø—ã—Ç–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API.")

    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ assistant_id –ø–æ modality
        if language != "ru":
            raise ValueError(f"Unsupported language: {language}")

        if not assistant_id:
            raise ValueError("Assistant ID is not configured.")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
        reset_ai_session(assistant_id, user_id=current_user.id)
        assistant_reply = _process_openai_request(text, assistant_id, user_id=current_user.id)

        logger.info("(—Ñ—É–Ω–∫—Ü–∏—è gramma_correction_ai) ‚úÖ –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        logger.debug(f"(—Ñ—É–Ω–∫—Ü–∏—è gramma_correction_ai) –û—Ç–≤–µ—Ç: {assistant_reply}")
        logger.info("---------------------------------------------------")
        return assistant_reply

    except Exception as e:
        logger.exception(f"(—Ñ—É–Ω–∫—Ü–∏—è gramma_correction_ai) ‚ùå Unexpected error: {str(e)}")
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ò–ò: error {e}")
  
  
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI. –ò—Å–ø–æ–ª—å–∑—É—é –≤ analyze_dinamics –≤ working_with_reports.py
def clean_raw_text(raw_text: str, user_id: int, assistant_id: str, max_attempts: int = 2) -> str:
    logger.info("(–§—É–Ω–∫—Ü–∏—è clean_raw_text) --------------------------------------")
    logger.info("[clean_raw_text] üöÄ –ù–∞—á–∞—Ç–∞ –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API.")
    logger.info("---------------------------------------------------")
    
    for attempt in range(max_attempts):
        try:
            cleaned = _process_openai_request(
                text=raw_text,
                assistant_id=assistant_id,
                user_id=user_id,
                file_id=None,
                clean_response=False
            )
            if cleaned:
                logger.info(f"[clean_raw_text] ‚úÖ –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —É—Å–ø–µ—à–Ω–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}.")
                logger.debug(f"[clean_raw_text] –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {cleaned}")
                logger.info("---------------------------------------------------")
                return cleaned
        except Exception as e:
            logger.warning(f"[clean_raw_text] ‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
        finally:
            reset_ai_session(assistant_id, user_id=user_id)

    logger.warning("[clean_raw_text] ‚ö†Ô∏è –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞—é –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç")
    logger.info("---------------------------------------------------")
    return raw_text






















































# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–µ—Ä–≤–æ–≥–æ –≤–∑–≥–ª—è–¥–∞. –ò—Å–ø–æ–ª—å–∑—É—é –≤ analyze_dinamics –≤ working_with_reports.py
def run_first_look_assistant(cleaned_text: str, template_text: list, user_id: int, assistant_id: str, max_attempts: int = 2) -> str:
    logger.info("(–§—É–Ω–∫—Ü–∏—è run_first_look_assistant) --------------------------------------")
    logger.info("[run_first_look_assistant] üöÄ –ù–∞—á–∞—Ç–∞ –ø–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ –≤–∑–≥–ª—è–¥–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API.")
    logger.info("---------------------------------------------------")
    
    converted_template_text = convert_template_json_to_text(template_text)
    if not converted_template_text:
        logger.error("[run_first_look_assistant] ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —à–∞–±–ª–æ–Ω –≤ —Ç–µ–∫—Å—Ç.")
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —à–∞–±–ª–æ–Ω –≤ —Ç–µ–∫—Å—Ç.")

    prompt = f"""TEMPLATE REPORT:
                {converted_template_text}
                RAW REPORT:
                {cleaned_text}
                """
                
    for attempt in range(max_attempts):
        try:
            result = _process_openai_request(
                text=prompt,
                assistant_id=assistant_id,
                user_id=user_id,
                file_id=None,
                clean_response=False
            )
            if result:
                logger.info(f"[run_first_look_assistant] ‚úÖ –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –≤–∑–≥–ª—è–¥–∞ —É—Å–ø–µ—à–Ω–æ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}.")
                logger.info(f"[run_first_look_assistant] –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {result}")
                logger.info("---------------------------------------------------")
                return result
        except Exception as e:
            logger.warning(f"[run_first_look_assistant] ‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
        finally:
            reset_ai_session(assistant_id, user_id=user_id)

    logger.error("[run_first_look_assistant] ‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ –≤–∑–≥–ª—è–¥–∞ –Ω–µ —É–¥–∞–ª–∏—Å—å")
    logger.info("---------------------------------------------------")
    raise ValueError("–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ –≤–∑–≥–ª—è–¥–∞ –Ω–µ —É–¥–∞–ª–∏—Å—å.")


# –û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API
def structure_report_text(template_text: list, report_text: str, user_id: int, assistant_id: str, max_attempts: int = 2) -> list:
    logger.info("(–§—É–Ω–∫—Ü–∏—è structure_report_text) --------------------------------------")
    logger.info("[structure_report_text] üöÄ –ù–∞—á–∞—Ç–∞ –ø–æ–ø—ã—Ç–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API.")
    logger.info("---------------------------------------------------")

    prompt = f"""REPORT TEMPLATE:
                {template_text}
                ORIGINAL MEDICAL REPORT TEXT:
                {report_text}
                """

    for attempt in range(max_attempts):
        try:
            result_text = _process_openai_request(
                text=prompt,
                assistant_id=assistant_id,
                user_id=user_id,
                file_id=None,
                clean_response=False,
            )
            if not result_text:
                logger.warning(f"[structure_report_text] ‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.")
                continue
            logger.info(f"[structure_report_text] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}.")
            
            try:
                # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ—Ç–≤–µ—Ç –∫–∞–∫ JSON
                parsed = pyjson.loads(result_text)
            except pyjson.JSONDecodeError:
                logger.warning(f"[structure_report_text] ‚ùå –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º JSON.")
                raise ValueError("–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º JSON. –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å.")
            
            if isinstance(parsed, dict):
                logger.info("[structure_report_text] ‚úÖ –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º. –î–æ—Å—Ç–∞—é report.")
                para_list = parsed.get("report", [])
                logger.info(f"[structure_report_text] ‚úÖ –£–¥–∞–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç—å report. –¢–µ–ø–µ—Ä—å report —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —Å–æ–¥–µ—Ä–∂–∞—â–∏–π: {len(para_list)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤.")
            elif isinstance(parsed, list):
                logger.info(f"[structure_report_text] üôå –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —è–≤–ª—è–µ—Ç—Å—è —Å–ø–∏—Å–∫–æ–º —Å {len(parsed)} —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏. –ü—Ä–æ–±—É—é –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –µ–≥–æ")
                para_list = parsed
            else:
                logger.error("[structure_report_text] ‚ùå –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –Ω–∏ —Å–ø–∏—Å–∫–æ–º, –Ω–∏ —Å–ª–æ–≤–∞—Ä–µ–º.")
                raise ValueError("–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –Ω–∏ —Å–ø–∏—Å–∫–æ–º, –Ω–∏ —Å–ª–æ–≤–∞—Ä–µ–º.")
            
            if para_list:
                logger.info(f"[structure_report_text] ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ —É—Å–ø–µ—à–Ω–æ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}.")
                logger.info(f"[structure_report_text] –û—Ç—á–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—é: {para_list}")
                logger.info("---------------------------------------------------")
                return para_list
        except Exception as e:
            logger.warning(f"[structure_report_text] ‚ùå –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
        finally:
            reset_ai_session(assistant_id, user_id=user_id)

    logger.error("[structure_report_text] ‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞ –Ω–µ —É–¥–∞–ª–∏—Å—å")
    logger.info("---------------------------------------------------")
    raise ValueError("–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞ –Ω–µ —É–¥–∞–ª–∏—Å—å.")


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ impression —Å –ø–æ–º–æ—â—å—é OpenAI.
def ai_impression_generation(assistant_id: str, user_id: int, report_text: str, file_id: str) -> str:
    logger.info("(–§—É–Ω–∫—Ü–∏—è ai_impression_generation) --------------------------------------")
    logger.info("[ai_impression_generation] üöÄ –ù–∞—á–∞—Ç–∞ –ø–æ–ø—ã—Ç–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ impression —Å –ø–æ–º–æ—â—å—é OpenAI API.")

    prompt = f"""
                MEDICAL REPORT TEXT:
                {report_text}
                """
    try:
        result = _process_openai_request(
            text=prompt,
            assistant_id=assistant_id,
            user_id=user_id,
            file_id=file_id,
            clean_response=False
        )
        if result:
            logger.info(f"[ai_impression_generation] ‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è impression —É—Å–ø–µ—à–Ω–∞.")
            logger.info("---------------------------------------------------")
            return result
        else:
            logger.error("[ai_impression_generation] ‚ùå –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø—É—Å—Ç.")
            raise ValueError("–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø—É—Å—Ç.")
    except Exception as e:
        logger.error(f"[ai_impression_generation] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ò–ò: {e}")
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ò–ò: {e}")
    finally:
        reset_ai_session(assistant_id, user_id=user_id)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –ø—Ä–∏ –ø–æ–º–æ—â–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ OPENAI_ASSISTANT_REDACTOR
def ai_report_check(assistant_id: str, user_id: int, report_text: str, today_date: str) -> str:
    logger.info("(–§—É–Ω–∫—Ü–∏—è ai_report_check) --------------------------------------")
    logger.info("[ai_report_check] üöÄ –ù–∞—á–∞—Ç–∞ –ø–æ–ø—ã—Ç–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ç—á–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI API.")

    prompt = f"""Today's date: 
                {today_date}
                MEDICAL REPORT TO CHECK:
                {report_text}
                """
    try:
        result = _process_openai_request(
            text=prompt,
            assistant_id=assistant_id,
            user_id=user_id,
            file_id=None,
            clean_response=False
        )
        if result:
            logger.info(f"[ai_report_check] ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—á–µ—Ç–∞ —É—Å–ø–µ—à–Ω–∞. –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {result}")
            logger.info("---------------------------------------------------")
            return result
        else:
            logger.error("[ai_report_check] ‚ùå –û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø—É—Å—Ç.")
            raise ValueError("–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø—É—Å—Ç.")
    except Exception as e:
        logger.error(f"[ai_report_check] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ò–ò: {e}")
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ò–ò: {e}")
    finally:
        reset_ai_session(assistant_id, user_id=user_id)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —à–∞–±–ª–æ–Ω–∞ –æ—Ç—á–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI. –ò—Å–ø–æ–ª—å–∑—É—é –≤ create_report_template –≤ working_with_reports.py
def ai_template_generator(template_text: str, assistant_id: str, user_id: int) -> dict:
    """
    Generates a report template based on the provided template data.
    """
    logger.info("(–§—É–Ω–∫—Ü–∏—è ai_template_generator) --------------------------------------")
    logger.info("[ai_template_generator] üöÄ –ù–∞—á–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —à–∞–±–ª–æ–Ω–∞ –æ—Ç—á–µ—Ç–∞.")
    
    generated_template = _process_openai_request(
        text=template_text,
        assistant_id=assistant_id,
        user_id=user_id,
        file_id=None,
        clean_response=False
    )
    # —Ä–∞—Å–ø–∞—Ä—Å–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç –≤ JSON
    try:
        json_generated_template = pyjson.loads(generated_template)
        logger.info(f"[ai_template_generator] ‚úÖ –®–∞–±–ª–æ–Ω —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {generated_template}")
        logger.info("---------------------------------------------------")
        return json_generated_template
    
    except pyjson.JSONDecodeError as e:
        logger.error(f"[ai_template_generator] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–∞—Ä—Å–∏–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}")
        raise ValueError("–û—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º JSON. –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å.")
    finally:
        reset_ai_session(assistant_id, user_id=user_id)
    
    

    
    