#working_with_reports.py

from flask import Blueprint, render_template, request, jsonify, send_file, g, current_app, json
from flask_security import current_user
import os
import json
from models import db, Report, ReportType, KeyWord, TailSentence, BodySentence, ReportTextSnapshot
from file_processing import save_to_word, extract_text_from_uploaded_file
from sentence_processing import group_keywords, split_sentences_if_needed, clean_and_normalize_text, compare_sentences_by_paragraph, preprocess_sentence, split_report_structure_for_ai, replace_head_sentences_with_fuzzy_check, merge_ai_response_into_skeleton, convert_template_json_to_text
from openai_api import _process_openai_request, reset_ai_session, count_tokens, clean_raw_text, run_first_look_assistant, structure_report_text
from utils.common import ensure_list
from logger import logger
from flask_security.decorators import auth_required
from spacy_manager import SpacyModel
from datetime import datetime
from celery_tasks import async_analyze_dynamics
from celery.result import AsyncResult



working_with_reports_bp = Blueprint('working_with_reports', __name__)

# Functions

# Routes

@working_with_reports_bp.route("/choosing_report", methods=['POST', 'GET'])
@auth_required()
def choosing_report(): 
    logger.info(f"(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ------------------------------------")
    logger.info(f"(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞")
    current_profile = g.current_profile
    report_types_and_subtypes = ReportType.get_types_with_subtypes(current_profile.id) 
    # current_profile_reports = Report.find_by_profile(current_profile.id)
    default_report_types = current_app.config.get("REPORT_TYPES_DEFAULT_RU", [])

    if request.method == "POST":
        logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) –ü–æ–ª—É—á–µ–Ω POST-–∑–∞–ø—Ä–æ—Å –Ω–∞ –≤—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞.")
        if request.is_json:
            data = request.get_json()
            rep_subtype = data.get("report_subtype")
            reports = Report.find_by_subtypes(rep_subtype)
            if not reports:
                logger.error("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —à–∞–±–ª–æ–Ω–æ–≤ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞")
                return jsonify({"status": "error", "message": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —à–∞–±–ª–æ–Ω–æ–≤ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞"}), 404
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
            logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ------------------------------------")
            logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è—é –¥–∞–Ω–Ω—ã–µ –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —à–∞–±–ª–æ–Ω–∞—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
            return jsonify({
                "status": "success",
                "reports": [
                    {"id": report.id, "report_name": report.report_name}
                    for report in reports
                ]
            })
    logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) –ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã.")
    return render_template(
        "choose_report.html",
        title="–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞",
        # user_reports=current_profile_reports,
        report_types_and_subtypes=report_types_and_subtypes,
        default_report_types=default_report_types,
    )


@working_with_reports_bp.route("/working_with_reports", methods=['GET'])
@auth_required()
def working_with_reports():
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ------------------------------------") 
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
    current_report_id = int(request.args.get("reportId"))
    full_name = request.args.get("fullname")
    birthdate = request.args.get("birthdate")
    report_number = request.args.get("reportNumber")
    
    if not current_report_id:
    
        logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
        return render_template("errors/error.html", message="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–¥—Ö–æ–¥—è—â–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª–µ –¥–ª—è —Ä–∞–±–æ—Ç—ã")
    try:
        report_data, paragraphs_data = Report.get_report_data(current_report_id)
        if report_data is None or paragraphs_data is None:
            logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ú–µ—Ç–æ–¥ get_report_data –≤–µ—Ä–Ω—É–ª None")
            return render_template("errors/error.html", message="–ú–µ—Ç–æ–¥ get_report_data –≤–µ—Ä–Ω—É–ª None")
    except Exception as e:
        logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {e}")
        return render_template("errors/error.html", message=f"–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {e}")
    
    # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    try:
        key_words_obj = KeyWord.get_keywords_for_report(g.current_profile.id, current_report_id)
        key_words_groups = group_keywords(key_words_obj)
    except Exception as e:
        logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
        return render_template("errors/error.html", message=f"–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–æ–ª–æ—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
    
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ------------------------------------")
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚úÖ –î–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏ –µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã. –ó–∞–≥—Ä—É–∂–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É")
    return render_template(
        "working_with_report.html", 
        title=report_data["report_name"],
        report_data=report_data,
        paragraphs_data=paragraphs_data,
        full_name=full_name,
        birthdate=birthdate,
        report_number=report_number,
        key_words_groups=key_words_groups,
    )


# –ú–∞—Ä—à—Ä—É—Ç –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–Ω–∞–ø—à–æ—Ç–æ–≤ (–Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –ø–æ—Ç–æ–º —É–±—Ä–∞—Ç—å –µ–≥–æ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –±–ª—é–ø—Ä–∏–Ω—Ç)
@working_with_reports_bp.route("/snapshots", methods=["GET"])
@auth_required()
def snapshots():
    logger.info(f"(–ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–Ω–∞–ø—à–æ—Ç–æ–≤) ------------------------------------")
    logger.info(f"(–ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–Ω–∞–ø—à–æ—Ç–æ–≤) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–Ω–∞–ø—à–æ—Ç–æ–≤")
    
    user_id = current_user.id
    current_profile = g.current_profile

    date_str = request.args.get("date")
    report_type = request.args.get("report_type")

    snapshots = []
    if date_str and report_type:
        try:
            date_obj = datetime.strptime(date_str, "%Y-%m-%d").date()
            report_type_int = int(report_type)
            snapshots = ReportTextSnapshot.find_by_date_and_type(user_id, date_obj, report_type_int)
        except Exception as e:
            logger.error(f"[report_snapshots] ‚ùå –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–Ω–∞–ø—à–æ—Ç–æ–≤: {e}")

    report_types = ReportType.find_by_profile(current_profile.id)

    return render_template(
        "snapshots.html",
        snapshots=snapshots,
        report_types=report_types
    )



@working_with_reports_bp.route("/snapshots_json", methods=["POST"])
@auth_required()
def snapshots_json():
    logger.info(f"(snapshots_json) ------------------------------------")
    logger.info(f"(snapshots_json) üöÄ –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Å–Ω–∞–ø—à–æ—Ç–æ–≤")
    logger.info(f"(snapshots_json) –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {request.get_json()}")
    try:
        data = request.get_json()
        date_str = data.get("date")
        report_type = int(data.get("report_type"))
        user_id = current_user.id

        date_obj = datetime.strptime(date_str, "%Y-%m-%d").date()
        snapshots = ReportTextSnapshot.find_by_date_and_type(user_id, date_obj, report_type)
        logger.info(f"(snapshots_json) ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(snapshots)} —Å–Ω–∞–ø—à–æ—Ç–æ–≤ –¥–ª—è –¥–∞—Ç—ã {date_str} –∏ —Ç–∏–ø–∞ {report_type}")

        data = render_template("partials/snapshot_results_snippet.html", snapshots=snapshots)
        logger.info(f"(snapshots_json) ‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–Ω–∞–ø—à–æ—Ç–æ–≤ —É—Å–ø–µ—à–Ω–æ –æ—Ç—Ä–µ–Ω–¥–µ—Ä–µ–Ω—ã")
        logger.info(f"(snapshots_json) ------------------------------------")
        return jsonify({"status": "success", "data": data}), 200

    except Exception as e:
        logger.error(f"(snapshots_json) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–Ω–∞–ø—à–æ—Ç–æ–≤: {e}")
        return jsonify({"status": "error", "message": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å–Ω–∞–ø—à–æ—Ç–æ–≤"}), 500
    
    

@working_with_reports_bp.route("/save_modified_sentences", methods=["POST"])
@auth_required()
def save_modified_sentences():
    """
    Processes and saves new or modified sentences to the database.
    Handles splitting of multi-sentence inputs and normalizes valid sentences.
    Keeps track of saved, skipped, and missed sentences.
    """
    
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ------------------------------------")
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        data = request.get_json()
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {data}")

        report_id = int(data.get("report_id"))
        sentences = ensure_list(data.get("sentences"))
        user_id = current_user.id
        report_type_id = Report.get_report_type_id(report_id)
        
        if not sentences or not report_id:
            logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–ª–∏ id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
            return jsonify({"status": "error", "message": "–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–ª–∏ id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞"}), 400
        
        processed_sentences = []  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, 
        #–æ—Ç–ø—Ä–∞–≤–ª—é –∏—Ö –ø–æ—Ç–æ–º –Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤ —Ñ—É–Ω–∫—Ü–∏—é compare_sentences_by_paragraph
        missed_count = 0  # –°—á—ë—Ç—á–∏–∫ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        

        for sentence_data in sentences:
            head_sentence_id = sentence_data.get("head_sentence_id", None)
            paragraph_id = sentence_data.get("paragraph_id")
            nativ_text = sentence_data.get("text")
            sentence_type = sentence_data.get("type")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
            if not paragraph_id or not nativ_text.strip():
                missed_count += 1
                logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –¥–∞–Ω–Ω—ã–µ –±–µ–∑ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç: {sentence_data}")
                continue  
            
            before_split_text = preprocess_sentence(nativ_text)
            
            if not before_split_text.strip():
                missed_count += 1
                continue  
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
            unsplited_sentences, splited_sentences = split_sentences_if_needed(before_split_text)

            if splited_sentences:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª—É—á–∞–∏ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º
                for idx, splited_sentence in enumerate(splited_sentences):
                    new_sentence_type = sentence_type
                    if splited_sentence.strip() == "":
                        missed_count += 1
                        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –ø—É—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {splited_sentence}")
                        continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                    if sentence_type == "body":
                        new_sentence_type = "body" if idx == 0 else "tail"
                    else:
                        new_sentence_type = "tail"
                    processed_sentences.append({
                        "paragraph_id": paragraph_id,
                        "head_sentence_id": head_sentence_id,
                        "sentence_type": new_sentence_type,
                        "text": splited_sentence.strip()
                    })
            else:
                for unsplited_sentence in unsplited_sentences:
                    if unsplited_sentence.strip() == "":
                        missed_count += 1
                        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –ø—É—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {unsplited_sentence}")
                        continue
                    processed_sentences.append({
                        "paragraph_id": paragraph_id,
                        "head_sentence_id": head_sentence_id,
                        "sentence_type": "body" if sentence_type == "body" else "tail",
                        "text": unsplited_sentence.strip()
                    })

        # –¢–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞–µ–º —Å —É–∂–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –≤ processed_sentences
        
        # –°–Ω–∞—á–∞–ª–∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏—Ö —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        comparsion_result = compare_sentences_by_paragraph(
                                                        processed_sentences,
                                                        report_id)
        
        new_sentences = comparsion_result["unique"]
        duplicates = comparsion_result["duplicates"]
        errors_count = comparsion_result["errors_count"]
        
        missed_count = 0  # –°—á—ë—Ç—á–∏–∫ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        saved_count = 0  # –°—á—ë—Ç—á–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        saved_sentences = []  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –æ—Ç—á–µ—Ç

        for sentence in new_sentences:
            processed_paragraph_id = sentence["paragraph_id"]
            head_sent_id = sentence["head_sentence_id"]
            new_sentence_text = clean_and_normalize_text(sentence["text"])
            sentence_type = sentence["sentence_type"]
            related_id = processed_paragraph_id if sentence_type == "tail" else head_sent_id
            try:
                if sentence_type == "tail":
                   new_sentence, sent_group = TailSentence.create(
                        sentence=new_sentence_text,
                        related_id=related_id,
                        user_id=user_id,
                        report_type_id=report_type_id,
                        comment="Added automatically"
                    )
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –≤ –∫–∞—á–µ—Å—Ç–≤–µ body_sentence 
                # –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –≥–ª–∞–≤–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                else:
                    if sentence["head_sentence_id"]:
                        new_sentence, sent_group = BodySentence.create(
                        sentence=new_sentence_text,
                        related_id=related_id,
                        user_id=user_id,
                        report_type_id=report_type_id,
                        comment="Added automatically",
                        )
                    else:
                        logger.warning(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω head_sentence_id –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {new_sentence_text}. –ü—Ä–æ–ø—É—Å–∫–∞—é –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ")
                        missed_count += 1   
                        continue
                saved_count += 1
                saved_sentences.append({"id": new_sentence.id, "related_id": related_id, "sentence_type": sentence_type, "text": new_sentence_text})
            except Exception as e:
                logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ùå –ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è ({new_sentence_text}) –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}. –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ —Å—á—ë—Ç—á–∏–∫")
                missed_count += 1

        sentences_adding_report = {
            "message": f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {len(processed_sentences)}.",
            "saved_count": saved_count,
            "skipped_count": len(processed_sentences) - saved_count,
            "missed_count": missed_count,
            "duplicates_count": len(duplicates),
            "errors_count": errors_count,
            "saved_sentences": saved_sentences,
            "duplicates": duplicates
        }

        rendered_html = render_template(
            "sentences_adding_report_snippet.html", 
            **sentences_adding_report)
        
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(processed_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.")
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ------------------------------------")
        return jsonify({
            "status": "success",
            "message": f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(processed_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.",
            "html": rendered_html
        }), 200

    except Exception as e:
        logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ùå –ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")
        return jsonify({"status": "error", "message": f"–ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"}), 500



@working_with_reports_bp.route("/export_to_word", methods=["POST"])
@auth_required()
def export_to_word():
    try:
        data = request.get_json()
        if data is None:
                return jsonify({"status": "error", "message": "No JSON data received"}), 400
        text = data.get("text")
        name = data.get("name") or "noname"
        subtype = data.get("subtype")
        report_type = data.get("report_type")
        birthdate = data.get("birthdate")
        reportnumber = data.get("reportnumber")
        scanParam = data.get("scanParam")
        side = data.get("side")

        if not text or not name or not subtype:
            return jsonify({"status": "error", "message": "Missing required information."}), 400
    except Exception as e:
        return jsonify({"status": "error", "message": f"Error processing request: {e}"}), 500

    try:
        file_path = save_to_word(text, name, subtype, report_type, birthdate, reportnumber, scanParam, side=side)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª
        if not os.path.exists(file_path):
            return jsonify({"status": "error", "message": "File not found"}), 500
        
        return send_file(file_path, as_attachment=True)
    except Exception as e:
        return jsonify({"status": "error", "message": f"Failed to export to Word: {e}"}), 500




@working_with_reports_bp.route("/save_report_snapshot", methods=["POST"])
@auth_required()
def save_report_snapshot():
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ------------------------------------")
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
    try:
        data = request.get_json()
        if not data:
            logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON")
            return jsonify({"status": "error", "message": "No JSON data received"}), 400
        report_id = data.get("report_id")
        text = data.get("text")
        if not report_id or not text:
            logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞ –∫–æ–ø–∏–∏")
            return jsonify({"status": "error", "message": "Missing required information."}), 400
        
        user_id = current_user.id
        
    except Exception as e:
        logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return jsonify({"status": "error", "message": f"Error processing request: {e}"}), 500

    try:
        ReportTextSnapshot.create(report_id, user_id, text)
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚úÖ –ö–æ–ø–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        return jsonify({"status": "success", "message": "Report snapshot saved"}), 200
    except Exception as e:
        logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–ø–∏—é –ø—Ä–æ—Ç–æ–∫–æ–ª–∞: {e}")
        return jsonify({"status": "error", "message": f"Failed to save report snapshot: {e}"}), 500
    


@working_with_reports_bp.route("/train_sentence_boundary", methods=["POST"])
@auth_required()
def train_sentence_boundary():
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Ä–∞–∑–º–µ—á–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ–≥–æ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è SpaCy.
    """
    data = request.get_json()
    text = data.get("text")
    sent_starts = data.get("sent_starts")
    if not text or not sent_starts:
        return jsonify({"status": "error", "message": "Missing text or sent_starts"}), 400
    
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ jsonl
        training_example = {
            "text": text,
            "sent_starts": sent_starts
        }

        file_path = os.path.join("spacy_training_data", "sent_boundary.jsonl")
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(training_example, ensure_ascii=False) + "\n")
        
        return jsonify({"status": "success", "message": "Example saved"}), 200
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500
    
    
    
# —Å—á–∏—Ç–∞—é —Ç–æ–∫–µ–Ω—ã –æ—Ç SpaCy —ç—Ç–æ –Ω–µ —á–∞—Å—Ç—å —Ä–∞–±–æ—Ç—ã —Å OpenAI,
@working_with_reports_bp.route("/get_spacy_tokens", methods=["POST"])
@auth_required()
def get_spacy_tokens():
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ç SpaCy —Å is_sent_start.
    """
    
    language = current_app.config.get("PROFILE_SETTINGS", {}).get("APP_LANGUAGE", "ru")

    data = request.get_json()
    text = data.get("text", "").strip()
    if not text:
        return jsonify({"status": "error", "message": "–¢–µ–∫—Å—Ç –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω"}), 400

    try:
        nlp = SpacyModel.get_instance(language)
        doc = nlp(text)
        tokens = [
            {
                "text": token.text,
                "idx": token.idx,
                "is_sent_start": token.is_sent_start
            }
            for token in doc
        ]
        return jsonify({"status": "success", "tokens": tokens}), 200

    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500
    
    
    
# editing_report.py
@working_with_reports_bp.route("/increase_sentence_weight", methods=["POST"])
@auth_required()
def increase_sentence_weight():
    logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ------------------------------------")
    logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
    data = request.get_json()
    sentence_id = data.get("sentence_id")
    group_id = data.get("group_id")
    sentence_type = data.get("sentence_type")
    
    logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {data}")

    if not sentence_id or not group_id or sentence_type not in ["body", "tail"]:
        logger.error(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
        return jsonify({"status": "error", "message": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö"}), 400

    try:
        if sentence_type == "body":
            BodySentence.increase_weight(sentence_id, group_id)
        else:
            TailSentence.increase_weight(sentence_id, group_id)
        logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ‚úÖ –í–µ—Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ —É–≤–µ–ª–∏—á–µ–Ω")
        return jsonify({"status": "success", "message": "–í–µ—Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —É–≤–µ–ª–∏—á–µ–Ω"}), 200
    except Exception as e:
        logger.error(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤–µ—Å–∞: {e}")
        return jsonify({"status": "error", "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤–µ—Å–∞: {e}"}), 500
    
     

# –ú–∞—Ä—à—Ä—É—Ç –¥–ª—è –ø–µ—Ä–µ–¥–µ–ª—ã–≤–∞–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ –æ–±—Ä–∞–∑—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —à–∞–±–ª–æ–Ω–∞
@working_with_reports_bp.route("/analyze_dynamics", methods=["POST"])
@auth_required()
def analyze_dynamics():
    logger.info(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ---------------------------------------------")
    logger.info(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) üöÄ –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏ –ø–æ —Ç–µ–∫—Å—Ç—É –∏ —à–∞–±–ª–æ–Ω—É –æ—Ç—á–µ—Ç–∞")
    logger.info("----------------------------------------------------------------")
    
    data = request.get_json()
    raw_text = data.get("raw_text", "").strip()
    report_id = data.get("report_id")
    user_id = current_user.id

    if not raw_text or not report_id:
        logger.error("–ù–µ –ø–µ—Ä–µ–¥–∞–Ω —Ç–µ–∫—Å—Ç –∏–ª–∏ report_id")
        return jsonify({"status": "error", "message": "–ù–µ –ø–µ—Ä–µ–¥–∞–Ω —Ç–µ–∫—Å—Ç –∏–ª–∏ report_id"}), 400

    report_data, sorted_parag = Report.get_report_data(report_id)
    if not report_data:
        logger.error("–®–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return jsonify({"status": "error", "message": "–®–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω"}), 404

    skeleton, template_text = split_report_structure_for_ai(sorted_parag)
    if not template_text or not skeleton:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —à–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞")
        return jsonify({"status": "error", "message": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —à–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞"}), 500

    logger.info(f"‚úÖ –®–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω. –ü–æ–ª—É—á–µ–Ω—ã json —Å—Ç—Ä—É–∫—Ç—É—Ä—ã skeleton –∏ template_text")
    
    try:
        task = async_analyze_dynamics.delay(raw_text, template_text, user_id, skeleton, report_id)
    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å celery –∑–∞–¥–∞—á—É async_analyze_dynamics: {e}")
        return jsonify({
            "status": "error",
            "message": f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏: {str(e)}"
        }), 500

    return jsonify({
        "status": "success",
        "message": "–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏ –∑–∞–ø—É—â–µ–Ω",
        "task_id": task.id,
    }), 200

       
        

# –ú–∞—Ä—à—Ä—É—Ç –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —ç—Ç–∞–ø–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —à–∞–±–ª–æ–Ω–∞ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º
@working_with_reports_bp.route("/analyze_dynamics_finalize", methods=["POST"])
def analyze_dynamics_finalize():
    logger.info(f"(–§–∏–Ω–∞–ª—å–Ω—ã–π —ç—Ç–∞–ø –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏) ------------------------------------")
    logger.info(f"(–§–∏–Ω–∞–ª—å–Ω—ã–π —ç—Ç–∞–ø –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏) üöÄ –ù–∞—á–∏–Ω–∞—é —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —ç—Ç–∞–ø –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏")
    
    try:
        data = request.get_json()
        result = data.get("result")  # —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã celery –∑–∞–¥–∞—á–∏
        report_id = data.get("report_id")
        skeleton = data.get("skeleton")

        if not result or not report_id:
            return jsonify({"status": "error", "message": "Missing required data"}), 400

        report_data, sorted_parag = Report.get_report_data(report_id)
        
        try:
            key_words_obj = KeyWord.get_keywords_for_report(g.current_profile.id, report_id)
            key_words_groups = group_keywords(key_words_obj)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {e}")
            key_words_groups = []
        

        merged_parag, misc_sentences = merge_ai_response_into_skeleton(skeleton, result)
        initial_report = replace_head_sentences_with_fuzzy_check(sorted_parag, merged_parag)

        new_html = render_template(
            "working_with_report.html",
            title=report_data["report_name"],
            report_data=report_data,
            paragraphs_data=initial_report,
            key_words_groups=key_words_groups,
        )
        return jsonify({
            "status": "success",
            "message": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç—á–µ—Ç–∞ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞",
            "report_data": report_data,
            "paragraphs_data": initial_report,
            "key_words_groups": key_words_groups,
            "html": new_html,
            "misc_sentences": misc_sentences,
        }), 200
    except Exception as e:
        logger.error(f"(–§–∏–Ω–∞–ª—å–Ω—ã–π —ç—Ç–∞–ø –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —ç—Ç–∞–ø–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏: {e}")
        return jsonify({"status": "error", "message": f"–û—à–∏–±–∫–∞ –∑–∞–º–µ–Ω—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {e}"}), 500






@working_with_reports_bp.route("/ocr_extract_text", methods=["POST"])
@auth_required()
def ocr_extract_text():
    logger.info(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ------------------------------------")
    logger.info(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
    try:
        file = request.files.get("file")
        if not file:
            logger.error(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return jsonify({"status": "error", "message": "No file uploaded"}), 400
        from file_processing import extract_text_from_uploaded_file
        text, error = extract_text_from_uploaded_file(file)
        if error:
            # –ï—Å–ª–∏ pdf ‚Äî –æ—Ç–¥–∞—Ç—å –∫–æ–¥ 200, –Ω–æ —Å–æ–æ–±—â–∏—Ç—å —á—Ç–æ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
            if "PDF files are not supported" in error:
                logger.info(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) üìÑ PDF —Ñ–∞–π–ª –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
                return jsonify({"status": "success", "text": "", "message": error}), 200
            logger.error(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {error}")
            return jsonify({"status": "error", "message": error}), 400
        logger.info(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ‚úÖ –¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω")
        return jsonify({"status": "success", "text": text}), 200
    except Exception as e:
        logger.error(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500