#working_with_reports.py

from flask import Blueprint, render_template, request, jsonify, send_file, g, current_app, json
from flask_security import current_user
import os
import json
from models import db, Report, ReportType, KeyWord, TailSentence, BodySentence, ReportTextSnapshot
from file_processing import save_to_word, extract_text_from_uploaded_file
from sentence_processing import group_keywords, split_sentences_if_needed, clean_and_normalize_text, compare_sentences_by_paragraph, preprocess_sentence, split_report_structure_for_ai, replace_head_sentences_with_fuzzy_check, merge_ai_response_into_skeleton
from openai_api import _process_openai_request, reset_ai_session, count_tokens
from utils.common import ensure_list
from logger import logger
from flask_security.decorators import auth_required
from spacy_manager import SpacyModel
from datetime import datetime



working_with_reports_bp = Blueprint('working_with_reports', __name__)

# Functions

# Routes

@working_with_reports_bp.route("/choosing_report", methods=['POST', 'GET'])
@auth_required()
def choosing_report(): 
    logger.info(f"(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ------------------------------------")
    logger.info(f"(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞")
    current_profile = g.current_profile
    report_types_and_subtypes = ReportType.get_types_with_subtypes(current_profile.id) 
    # current_profile_reports = Report.find_by_profile(current_profile.id)
    default_report_types = current_app.config.get("REPORT_TYPES_DEFAULT_RU", [])

    if request.method == "POST":
        logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) –ü–æ–ª—É—á–µ–Ω POST-–∑–∞–ø—Ä–æ—Å –Ω–∞ –≤—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞.")
        if request.is_json:
            data = request.get_json()
            rep_subtype = data.get("report_subtype")
            reports = Report.find_by_subtypes(rep_subtype)
            if not reports:
                logger.error("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —à–∞–±–ª–æ–Ω–æ–≤ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞")
                return jsonify({"status": "error", "message": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —à–∞–±–ª–æ–Ω–æ–≤ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞"}), 404
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
            logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ------------------------------------")
            logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è—é –¥–∞–Ω–Ω—ã–µ –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —à–∞–±–ª–æ–Ω–∞—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
            return jsonify({
                "status": "success",
                "reports": [
                    {"id": report.id, "report_name": report.report_name}
                    for report in reports
                ]
            })
    logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) –ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã.")
    return render_template(
        "choose_report.html",
        title="–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞",
        # user_reports=current_profile_reports,
        report_types_and_subtypes=report_types_and_subtypes,
        default_report_types=default_report_types,
    )


@working_with_reports_bp.route("/working_with_reports", methods=['GET'])
@auth_required()
def working_with_reports():
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ------------------------------------") 
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
    current_report_id = int(request.args.get("reportId"))
    full_name = request.args.get("fullname")
    birthdate = request.args.get("birthdate")
    report_number = request.args.get("reportNumber")
    
    if not current_report_id:
    
        logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
        return render_template("errors/error.html", message="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–¥—Ö–æ–¥—è—â–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª–µ –¥–ª—è —Ä–∞–±–æ—Ç—ã")
    try:
        report_data, paragraphs_data = Report.get_report_data(current_report_id)
        if report_data is None or paragraphs_data is None:
            logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ú–µ—Ç–æ–¥ get_report_data –≤–µ—Ä–Ω—É–ª None")
            return render_template("errors/error.html", message="–ú–µ—Ç–æ–¥ get_report_data –≤–µ—Ä–Ω—É–ª None")
    except Exception as e:
        logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {e}")
        return render_template("errors/error.html", message=f"–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {e}")
    
    # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    try:
        key_words_obj = KeyWord.get_keywords_for_report(g.current_profile.id, current_report_id)
        key_words_groups = group_keywords(key_words_obj)
    except Exception as e:
        logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
        return render_template("errors/error.html", message=f"–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–æ–ª–æ—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
    
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ------------------------------------")
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚úÖ –î–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏ –µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã. –ó–∞–≥—Ä—É–∂–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É")
    return render_template(
        "working_with_report.html", 
        title=report_data["report_name"],
        report_data=report_data,
        paragraphs_data=paragraphs_data,
        full_name=full_name,
        birthdate=birthdate,
        report_number=report_number,
        key_words_groups=key_words_groups,
    )


# –ú–∞—Ä—à—Ä—É—Ç –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–Ω–∞–ø—à–æ—Ç–æ–≤ (–Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –ø–æ—Ç–æ–º —É–±—Ä–∞—Ç—å –µ–≥–æ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –±–ª—é–ø—Ä–∏–Ω—Ç)
@working_with_reports_bp.route("/snapshots", methods=["GET"])
@auth_required()
def snapshots():
    logger.info(f"(–ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–Ω–∞–ø—à–æ—Ç–æ–≤) ------------------------------------")
    logger.info(f"(–ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–Ω–∞–ø—à–æ—Ç–æ–≤) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–Ω–∞–ø—à–æ—Ç–æ–≤")
    
    user_id = current_user.id
    current_profile = g.current_profile

    date_str = request.args.get("date")
    report_type = request.args.get("report_type")

    snapshots = []
    if date_str and report_type:
        try:
            date_obj = datetime.strptime(date_str, "%Y-%m-%d").date()
            report_type_int = int(report_type)
            snapshots = ReportTextSnapshot.find_by_date_and_type(user_id, date_obj, report_type_int)
        except Exception as e:
            logger.error(f"[report_snapshots] ‚ùå –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–Ω–∞–ø—à–æ—Ç–æ–≤: {e}")

    report_types = ReportType.find_by_profile(current_profile.id)

    return render_template(
        "snapshots.html",
        snapshots=snapshots,
        report_types=report_types
    )



@working_with_reports_bp.route("/snapshots_json", methods=["POST"])
@auth_required()
def snapshots_json():
    logger.info(f"(snapshots_json) ------------------------------------")
    logger.info(f"(snapshots_json) üöÄ –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Å–Ω–∞–ø—à–æ—Ç–æ–≤")
    logger.info(f"(snapshots_json) –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {request.get_json()}")
    try:
        data = request.get_json()
        date_str = data.get("date")
        report_type = int(data.get("report_type"))
        user_id = current_user.id

        date_obj = datetime.strptime(date_str, "%Y-%m-%d").date()
        snapshots = ReportTextSnapshot.find_by_date_and_type(user_id, date_obj, report_type)
        logger.info(f"(snapshots_json) ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(snapshots)} —Å–Ω–∞–ø—à–æ—Ç–æ–≤ –¥–ª—è –¥–∞—Ç—ã {date_str} –∏ —Ç–∏–ø–∞ {report_type}")

        data = render_template("partials/snapshot_results_snippet.html", snapshots=snapshots)
        logger.info(f"(snapshots_json) ‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–Ω–∞–ø—à–æ—Ç–æ–≤ —É—Å–ø–µ—à–Ω–æ –æ—Ç—Ä–µ–Ω–¥–µ—Ä–µ–Ω—ã")
        logger.info(f"(snapshots_json) ------------------------------------")
        return jsonify({"status": "success", "data": data}), 200

    except Exception as e:
        logger.error(f"(snapshots_json) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–Ω–∞–ø—à–æ—Ç–æ–≤: {e}")
        return jsonify({"status": "error", "message": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å–Ω–∞–ø—à–æ—Ç–æ–≤"}), 500
    
    

@working_with_reports_bp.route("/save_modified_sentences", methods=["POST"])
@auth_required()
def save_modified_sentences():
    """
    Processes and saves new or modified sentences to the database.
    Handles splitting of multi-sentence inputs and normalizes valid sentences.
    Keeps track of saved, skipped, and missed sentences.
    """
    
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ------------------------------------")
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        data = request.get_json()
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {data}")

        report_id = int(data.get("report_id"))
        sentences = ensure_list(data.get("sentences"))
        user_id = current_user.id
        report_type_id = Report.get_report_type_id(report_id)
        
        if not sentences or not report_id:
            logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–ª–∏ id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
            return jsonify({"status": "error", "message": "–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–ª–∏ id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞"}), 400
        
        processed_sentences = []  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, 
        #–æ—Ç–ø—Ä–∞–≤–ª—é –∏—Ö –ø–æ—Ç–æ–º –Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤ —Ñ—É–Ω–∫—Ü–∏—é compare_sentences_by_paragraph
        missed_count = 0  # –°—á—ë—Ç—á–∏–∫ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        

        for sentence_data in sentences:
            head_sentence_id = sentence_data.get("head_sentence_id", None)
            paragraph_id = sentence_data.get("paragraph_id")
            nativ_text = sentence_data.get("text")
            sentence_type = sentence_data.get("type")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
            if not paragraph_id or not nativ_text.strip():
                missed_count += 1
                logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –¥–∞–Ω–Ω—ã–µ –±–µ–∑ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç: {sentence_data}")
                continue  
            
            before_split_text = preprocess_sentence(nativ_text)
            
            if not before_split_text.strip():
                missed_count += 1
                continue  
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
            unsplited_sentences, splited_sentences = split_sentences_if_needed(before_split_text)

            if splited_sentences:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª—É—á–∞–∏ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º
                for idx, splited_sentence in enumerate(splited_sentences):
                    new_sentence_type = sentence_type
                    if splited_sentence.strip() == "":
                        missed_count += 1
                        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –ø—É—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {splited_sentence}")
                        continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                    if sentence_type == "body":
                        new_sentence_type = "body" if idx == 0 else "tail"
                    else:
                        new_sentence_type = "tail"
                    processed_sentences.append({
                        "paragraph_id": paragraph_id,
                        "head_sentence_id": head_sentence_id,
                        "sentence_type": new_sentence_type,
                        "text": splited_sentence.strip()
                    })
            else:
                for unsplited_sentence in unsplited_sentences:
                    if unsplited_sentence.strip() == "":
                        missed_count += 1
                        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –ø—É—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {unsplited_sentence}")
                        continue
                    processed_sentences.append({
                        "paragraph_id": paragraph_id,
                        "head_sentence_id": head_sentence_id,
                        "sentence_type": "body" if sentence_type == "body" else "tail",
                        "text": unsplited_sentence.strip()
                    })

        # –¢–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞–µ–º —Å —É–∂–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –≤ processed_sentences
        
        # –°–Ω–∞—á–∞–ª–∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏—Ö —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        comparsion_result = compare_sentences_by_paragraph(
                                                        processed_sentences,
                                                        report_id)
        
        new_sentences = comparsion_result["unique"]
        duplicates = comparsion_result["duplicates"]
        errors_count = comparsion_result["errors_count"]
        
        missed_count = 0  # –°—á—ë—Ç—á–∏–∫ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        saved_count = 0  # –°—á—ë—Ç—á–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        saved_sentences = []  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –æ—Ç—á–µ—Ç

        for sentence in new_sentences:
            processed_paragraph_id = sentence["paragraph_id"]
            head_sent_id = sentence["head_sentence_id"]
            new_sentence_text = clean_and_normalize_text(sentence["text"])
            sentence_type = sentence["sentence_type"]
            related_id = processed_paragraph_id if sentence_type == "tail" else head_sent_id
            try:
                if sentence_type == "tail":
                   new_sentence, sent_group = TailSentence.create(
                        sentence=new_sentence_text,
                        related_id=related_id,
                        user_id=user_id,
                        report_type_id=report_type_id,
                        comment="Added automatically"
                    )
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –≤ –∫–∞—á–µ—Å—Ç–≤–µ body_sentence 
                # –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –≥–ª–∞–≤–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                else:
                    if sentence["head_sentence_id"]:
                        new_sentence, sent_group = BodySentence.create(
                        sentence=new_sentence_text,
                        related_id=related_id,
                        user_id=user_id,
                        report_type_id=report_type_id,
                        comment="Added automatically",
                        )
                    else:
                        logger.warning(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω head_sentence_id –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {new_sentence_text}. –ü—Ä–æ–ø—É—Å–∫–∞—é –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ")
                        missed_count += 1   
                        continue
                saved_count += 1
                saved_sentences.append({"id": new_sentence.id, "related_id": related_id, "sentence_type": sentence_type, "text": new_sentence_text})
            except Exception as e:
                logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ùå –ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è ({new_sentence_text}) –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}. –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ —Å—á—ë—Ç—á–∏–∫")
                missed_count += 1

        sentences_adding_report = {
            "message": f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {len(processed_sentences)}.",
            "saved_count": saved_count,
            "skipped_count": len(processed_sentences) - saved_count,
            "missed_count": missed_count,
            "duplicates_count": len(duplicates),
            "errors_count": errors_count,
            "saved_sentences": saved_sentences,
            "duplicates": duplicates
        }

        rendered_html = render_template(
            "sentences_adding_report_snippet.html", 
            **sentences_adding_report)
        
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(processed_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.")
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ------------------------------------")
        return jsonify({
            "status": "success",
            "message": f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(processed_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.",
            "html": rendered_html
        }), 200

    except Exception as e:
        logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ùå –ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")
        return jsonify({"status": "error", "message": f"–ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"}), 500



@working_with_reports_bp.route("/export_to_word", methods=["POST"])
@auth_required()
def export_to_word():
    try:
        data = request.get_json()
        if data is None:
                return jsonify({"status": "error", "message": "No JSON data received"}), 400
        text = data.get("text")
        name = data.get("name") or "noname"
        subtype = data.get("subtype")
        report_type = data.get("report_type")
        birthdate = data.get("birthdate")
        reportnumber = data.get("reportnumber")
        scanParam = data.get("scanParam")
        side = data.get("side")

        if not text or not name or not subtype:
            return jsonify({"status": "error", "message": "Missing required information."}), 400
    except Exception as e:
        return jsonify({"status": "error", "message": f"Error processing request: {e}"}), 500

    try:
        file_path = save_to_word(text, name, subtype, report_type, birthdate, reportnumber, scanParam, side=side)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª
        if not os.path.exists(file_path):
            return jsonify({"status": "error", "message": "File not found"}), 500
        
        return send_file(file_path, as_attachment=True)
    except Exception as e:
        return jsonify({"status": "error", "message": f"Failed to export to Word: {e}"}), 500




@working_with_reports_bp.route("/save_report_snapshot", methods=["POST"])
@auth_required()
def save_report_snapshot():
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ------------------------------------")
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
    try:
        data = request.get_json()
        if not data:
            logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON")
            return jsonify({"status": "error", "message": "No JSON data received"}), 400
        report_id = data.get("report_id")
        text = data.get("text")
        if not report_id or not text:
            logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞ –∫–æ–ø–∏–∏")
            return jsonify({"status": "error", "message": "Missing required information."}), 400
        
        user_id = current_user.id
        
    except Exception as e:
        logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return jsonify({"status": "error", "message": f"Error processing request: {e}"}), 500

    try:
        ReportTextSnapshot.create(report_id, user_id, text)
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚úÖ –ö–æ–ø–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        return jsonify({"status": "success", "message": "Report snapshot saved"}), 200
    except Exception as e:
        logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–ø–∏—é –ø—Ä–æ—Ç–æ–∫–æ–ª–∞: {e}")
        return jsonify({"status": "error", "message": f"Failed to save report snapshot: {e}"}), 500
    


@working_with_reports_bp.route("/train_sentence_boundary", methods=["POST"])
@auth_required()
def train_sentence_boundary():
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Ä–∞–∑–º–µ—á–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ–≥–æ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è SpaCy.
    """
    data = request.get_json()
    text = data.get("text")
    sent_starts = data.get("sent_starts")
    if not text or not sent_starts:
        return jsonify({"status": "error", "message": "Missing text or sent_starts"}), 400
    
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ jsonl
        training_example = {
            "text": text,
            "sent_starts": sent_starts
        }

        file_path = os.path.join("spacy_training_data", "sent_boundary.jsonl")
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(training_example, ensure_ascii=False) + "\n")
        
        return jsonify({"status": "success", "message": "Example saved"}), 200
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500
    
    
    
# —Å—á–∏—Ç–∞—é —Ç–æ–∫–µ–Ω—ã –æ—Ç SpaCy —ç—Ç–æ –Ω–µ —á–∞—Å—Ç—å —Ä–∞–±–æ—Ç—ã —Å OpenAI,
@working_with_reports_bp.route("/get_spacy_tokens", methods=["POST"])
@auth_required()
def get_spacy_tokens():
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ç SpaCy —Å is_sent_start.
    """
    
    language = current_app.config.get("PROFILE_SETTINGS", {}).get("APP_LANGUAGE", "ru")

    data = request.get_json()
    text = data.get("text", "").strip()
    if not text:
        return jsonify({"status": "error", "message": "–¢–µ–∫—Å—Ç –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω"}), 400

    try:
        nlp = SpacyModel.get_instance(language)
        doc = nlp(text)
        tokens = [
            {
                "text": token.text,
                "idx": token.idx,
                "is_sent_start": token.is_sent_start
            }
            for token in doc
        ]
        return jsonify({"status": "success", "tokens": tokens}), 200

    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500
    
    
    
# editing_report.py
@working_with_reports_bp.route("/increase_sentence_weight", methods=["POST"])
@auth_required()
def increase_sentence_weight():
    logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ------------------------------------")
    logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
    data = request.get_json()
    sentence_id = data.get("sentence_id")
    group_id = data.get("group_id")
    sentence_type = data.get("sentence_type")
    
    logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {data}")

    if not sentence_id or not group_id or sentence_type not in ["body", "tail"]:
        logger.error(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
        return jsonify({"status": "error", "message": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö"}), 400

    try:
        if sentence_type == "body":
            BodySentence.increase_weight(sentence_id, group_id)
        else:
            TailSentence.increase_weight(sentence_id, group_id)
        logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ‚úÖ –í–µ—Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ —É–≤–µ–ª–∏—á–µ–Ω")
        return jsonify({"status": "success", "message": "–í–µ—Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —É–≤–µ–ª–∏—á–µ–Ω"}), 200
    except Exception as e:
        logger.error(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤–µ—Å–∞: {e}")
        return jsonify({"status": "error", "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤–µ—Å–∞: {e}"}), 500
    
    

@working_with_reports_bp.route("/analyze_dynamics", methods=["POST"])
@auth_required()
def analyze_dynamics():
    logger.info(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ------------------------------------")
    logger.info(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) üöÄ –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏ –ø–æ —Ç–µ–∫—Å—Ç—É –∏ —à–∞–±–ª–æ–Ω—É –æ—Ç—á–µ—Ç–∞")
    data = request.get_json()
    raw_text = data.get("raw_text", "").strip()
    report_id = data.get("report_id")
    logger.info(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: raw_text={raw_text[:50]}..., report_id={report_id}")

    if not raw_text or not report_id:
        logger.error(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) –ù–µ –ø–µ—Ä–µ–¥–∞–Ω —Ç–µ–∫—Å—Ç –∏–ª–∏ report_id")
        return jsonify({"status": "error", "message": "–ù–µ –ø–µ—Ä–µ–¥–∞–Ω —Ç–µ–∫—Å—Ç –∏–ª–∏ report_id"}), 400

    report_data, sorted_parag = Report.get_report_data(report_id)
    if not report_data:
        logger.error(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) –®–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return jsonify({"status": "error", "message": "–®–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω"}), 404

    # –ü–æ–ø—ã—Ç–∫–∞ —Å–æ–±—Ä–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –ø–µ—Ä–µ—Ä–µ–Ω–¥–µ—Ä–∏–≤–∞–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–∏ —É—Å–ø—à–Ω–æ–º —Å–∏–Ω—Ç–µ–∑–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
    try:
        key_words_obj = KeyWord.get_keywords_for_report(g.current_profile.id, report_id)
        key_words_groups = group_keywords(key_words_obj)
    except Exception as e:
        logger.error(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚ùå –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
        key_words_groups = []
    
    # –°–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –æ—Ç—á–µ—Ç–∞
    skeleton, template_text = split_report_structure_for_ai(sorted_parag)
    if not template_text or not skeleton:
        logger.error(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —à–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞")
        return jsonify({"status": "error", "message": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —à–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞"}), 500
    logger.info(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) –®–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –ò–ò: {template_text[:3]}...{template_text[-3:]}") 
    logger.info(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) –°–∫–µ–ª–µ—Ç —à–∞–±–ª–æ–Ω–∞ –æ—Ç—á–µ—Ç–∞: {skeleton[:3]}...{skeleton[-3:]}")

    structurer_assistant_id = current_app.config.get("OPENAI_ASSISTANT_DYNAMIC_STRUCTURER")
    cleaner_assistant_id = current_app.config.get("OPENAI_ASSISTANT_TEXT_CLEANER")

    if not structurer_assistant_id or not cleaner_assistant_id:
        logger.error(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å ID –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ OpenAI –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è")
        return jsonify({"status": "error", "message": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å ID –ò–ò –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è"}), 500
    
    try:
        # –°–Ω–∞—á–∞–ª–∞ –æ—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö –∫—É—Å–∫–æ–≤ —Ñ–∏–æ, –Ω–∞–∑–≤–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏ —Ç.–¥. –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Ç–æ–∫–æ–ª
        cleaned_text = _process_openai_request(
            text=raw_text,
            assistant_id=cleaner_assistant_id,
            file_id=None,
            clean_response=False,
        )
        if not cleaned_text:
            logger.warning(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚ùå –ü–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø—Ä–æ–±—É—é –µ—â–µ —Ä–∞–∑...")
            # –í—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞
            cleaned_text = _process_openai_request(
                text=raw_text,
                assistant_id=cleaner_assistant_id,
                file_id=None,
                clean_response=False,
            )
            if not cleaned_text:
                logger.warning(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚ùå –í—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Ç–æ–∂–µ –Ω–µ —É–¥–∞–ª–∞—Å—å ‚Äî –∏—Å–ø–æ–ª—å–∑—É—é –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –æ—á–∏—Å—Ç–∫–∏")
                cleaned_text = raw_text # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –æ—á–∏—Å—Ç–∫–∏
        
    except Exception as e:
        logger.error(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
        cleaned_text = raw_text  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –æ—á–∏—Å—Ç–∫–∏
    
    logger.info(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚úÖ –¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω –æ—Ç –º—É—Å–æ—Ä–∞")
    print("--------------------------------------------")
    print(f"–ü–æ–ª—É—á–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –æ—Ç –º—É—Å–æ—Ä–∞: {cleaned_text}")
    print("--------------------------------------------")
    
    # –¢–µ–ø–µ—Ä—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —à–∞–±–ª–æ–Ω–æ–º
    prompt_structuring = f"""
                This is the report template:
                {template_text}
                This is the original medical report text:
                {cleaned_text}
                """
   
    try:
        result_text = _process_openai_request(
            text=prompt_structuring,
            assistant_id=structurer_assistant_id,
            file_id=None,
            clean_response=False,
        )
    except Exception as e:
        logger.error(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚ùå –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ OpenAI: {e}")
        # –í—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞ –Ω–∞ —Å–ª—É—á–∞–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –æ—à–∏–±–∫–∏
        try:
            result_text = _process_openai_request(
                text=prompt_structuring,
                assistant_id=structurer_assistant_id,
                file_id=None,
                clean_response=False,
            )
            logger.info("(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚úÖ 2Ô∏è‚É£ –í—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞ –≤—ã–∑–æ–≤–∞ OpenAI –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ")
        except Exception as e2:
            logger.error(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚ùå‚ùå 2Ô∏è‚É£ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Ç–æ–∂–µ –Ω–µ —É–¥–∞–ª–∞—Å—å: {e2}")
            return jsonify({
                "status": "error",
                "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–µ –≤—ã–∑–æ–≤–∞ OpenAI: {e2}"
            }), 500

    print("--------------------------------------------")
    print(f"–ü–æ–ª—É—á–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è: {result_text}")
    print("--------------------------------------------")
    parsed = json.loads(result_text)
    result = parsed.get("items", [])
    try:
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–æ skeleton. –¢—É—Ç –Ω–µ –æ–∂–∏–¥–∞—é –æ—à–∏–±–æ–∫.
        merged_parag, misc_sentences = merge_ai_response_into_skeleton(skeleton, result)
        # –≠—Ç–æ –ø–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∑–∞–º–µ–Ω—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞—Ö 
        initial_report = replace_head_sentences_with_fuzzy_check(sorted_parag, merged_parag)
        logger.info("(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚úÖ –£–¥–∞–ª–æ—Å—å –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –∑–∞–º–µ–Ω–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –ø–µ—Ä–≤–æ–π –ø–æ–ø—ã—Ç–∫–∏ 1Ô∏è‚É£.")

        new_html = render_template(
            "working_with_report.html",
            title=report_data["report_name"],
            report_data=report_data,
            paragraphs_data=initial_report,
            key_words_groups=key_words_groups,
        )
        print(misc_sentences)
        return jsonify({
            "status": "success",
            "message": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç—á–µ—Ç–∞ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞",
            "report_data": report_data,
            "paragraphs_data": initial_report,
            "key_words_groups": key_words_groups,
            "html": new_html,
            "misc_sentences": misc_sentences,
        }), 200
    except Exception as e:
        error_message = str(e)
        logger.error(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç—á–µ—Ç–∞ –∏ –∑–∞–º–µ–Ω–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {error_message}")

        try:
            # –í—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞
            retry_prompt = f"""
                            The following error occurred while analyzing the generated report structure:
                            {error_message}
                            Ensure that you use only the information from the original medical report and the given template.
                            """
            retry_response = _process_openai_request(
                text=retry_prompt,
                assistant_id=structurer_assistant_id,
                file_id=None,
                clean_response=False
            )
            
            print("--------------------------------------------")
            print(f"–ü–æ–ª—É—á–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è, –≤—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞: {retry_response}")
            print("--------------------------------------------")
            
            parsed_retry = json.loads(retry_response)
            result = parsed_retry.get("items", [])
            
            try:
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–æ skeleton (–≤—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞).
                merged_parag, misc_sentences = merge_ai_response_into_skeleton(skeleton, result)
                # –í—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∑–∞–º–µ–Ω—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞—Ö
                initial_report = replace_head_sentences_with_fuzzy_check(sorted_parag, merged_parag)
                logger.info("(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚úÖ –£–¥–∞–ª–æ—Å—å –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –∑–∞–º–µ–Ω–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å–æ –≤—Ç–æ—Ä–æ–π –ø–æ–ø—ã—Ç–∫–∏.")
            except Exception as e3:
                logger.error(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–µ –∑–∞–º–µ–Ω—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {e3}")
                return jsonify({"status": "error", "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–µ –∑–∞–º–µ–Ω—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {e3}"}), 500
            
            new_html = render_template(
                "working_with_report.html",
                title=report_data["report_name"],
                report_data=report_data,
                paragraphs_data=initial_report,
                key_words_groups=key_words_groups,
            )
            print(misc_sentences)
            return jsonify({
                "status": "success",
                "message": "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç—á–µ—Ç–∞ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏",
                "report_data": report_data,
                "paragraphs_data": initial_report,
                "key_words_groups": key_words_groups,
                "html": new_html,
                "misc_sentences": misc_sentences,
            }), 200
        except Exception as e2:
            logger.error(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–µ –ø–æ—Å–ª–µ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º: {e2}")
            return jsonify({"status": "error", "message": f"–û—à–∏–±–∫–∞ –¥–∞–∂–µ –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏: {e2}. –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª"}), 500
    finally:
        reset_ai_session(assistant_id=structurer_assistant_id)
        reset_ai_session(assistant_id=cleaner_assistant_id)
        logger.info(f"(–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏) üìå –°–µ—Å—Å–∏–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤ OpenAI —É—Å–ø–µ—à–Ω–æ —Å–±—Ä–æ—à–µ–Ω—ã")
        
        


@working_with_reports_bp.route("/ocr_extract_text", methods=["POST"])
@auth_required()
def ocr_extract_text():
    logger.info(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ------------------------------------")
    logger.info(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
    try:
        file = request.files.get("file")
        if not file:
            logger.error(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return jsonify({"status": "error", "message": "No file uploaded"}), 400
        from file_processing import extract_text_from_uploaded_file
        text, error = extract_text_from_uploaded_file(file)
        if error:
            # –ï—Å–ª–∏ pdf ‚Äî –æ—Ç–¥–∞—Ç—å –∫–æ–¥ 200, –Ω–æ —Å–æ–æ–±—â–∏—Ç—å —á—Ç–æ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
            if "PDF files are not supported" in error:
                logger.info(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) üìÑ PDF —Ñ–∞–π–ª –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
                return jsonify({"status": "success", "text": "", "message": error}), 200
            logger.error(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {error}")
            return jsonify({"status": "error", "message": error}), 400
        logger.info(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ‚úÖ –¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω")
        return jsonify({"status": "success", "text": text}), 200
    except Exception as e:
        logger.error(f"(–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500