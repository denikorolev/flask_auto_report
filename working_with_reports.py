#working_with_reports.py

from flask import Blueprint, render_template, request, jsonify, send_file, g, current_app, json
from flask_security import current_user
import os
from models import db, Report, ReportType, KeyWord, TailSentence, BodySentence, ReportTextSnapshot
from file_processing import save_to_word
from sentence_processing import group_keywords, split_sentences_if_needed, clean_and_normalize_text, compare_sentences_by_paragraph, preprocess_sentence
from utils.common import ensure_list
from logger import logger
from flask_security.decorators import auth_required
from spacy_manager import SpacyModel
from datetime import datetime



working_with_reports_bp = Blueprint('working_with_reports', __name__)

# Functions

# Routes

@working_with_reports_bp.route("/choosing_report", methods=['POST', 'GET'])
@auth_required()
def choosing_report(): 
    logger.info(f"(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ------------------------------------")
    logger.info(f"(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞")
    current_profile = g.current_profile
    report_types_and_subtypes = ReportType.get_types_with_subtypes(current_profile.id) 
    # current_profile_reports = Report.find_by_profile(current_profile.id)
    default_report_types = current_app.config.get("REPORT_TYPES_DEFAULT_RU", [])

    if request.method == "POST":
        logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) –ü–æ–ª—É—á–µ–Ω POST-–∑–∞–ø—Ä–æ—Å –Ω–∞ –≤—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞.")
        if request.is_json:
            data = request.get_json()
            rep_subtype = data.get("report_subtype")
            reports = Report.find_by_subtypes(rep_subtype)
            if not reports:
                logger.error("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —à–∞–±–ª–æ–Ω–æ–≤ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞")
                return jsonify({"status": "error", "message": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —à–∞–±–ª–æ–Ω–æ–≤ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞"}), 404
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON
            logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ------------------------------------")
            logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è—é –¥–∞–Ω–Ω—ã–µ –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —à–∞–±–ª–æ–Ω–∞—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
            return jsonify({
                "status": "success",
                "reports": [
                    {"id": report.id, "report_name": report.report_name}
                    for report in reports
                ]
            })
    logger.info("(–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) –ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã.")
    return render_template(
        "choose_report.html",
        title="–í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞",
        # user_reports=current_profile_reports,
        report_types_and_subtypes=report_types_and_subtypes,
        default_report_types=default_report_types,
    )


@working_with_reports_bp.route("/working_with_reports", methods=['GET'])
@auth_required()
def working_with_reports():
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ------------------------------------") 
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
    current_report_id = int(request.args.get("reportId"))
    full_name = request.args.get("fullname")
    birthdate = request.args.get("birthdate")
    report_number = request.args.get("reportNumber")
    
    
    if not current_report_id:
        logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
        return render_template("errors/error.html", message="–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–¥—Ö–æ–¥—è—â–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª–µ –¥–ª—è —Ä–∞–±–æ—Ç—ã")
    try:
        report_data, paragraphs_data = Report.get_report_data(current_report_id)
        if report_data is None or paragraphs_data is None:
            logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ú–µ—Ç–æ–¥ get_report_data –≤–µ—Ä–Ω—É–ª None")
            return render_template("errors/error.html", message="–ú–µ—Ç–æ–¥ get_report_data –≤–µ—Ä–Ω—É–ª None")
    except Exception as e:
        logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {e}")
        return render_template("errors/error.html", message=f"–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {e}")
    
    # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    try:
        key_words_obj = KeyWord.get_keywords_for_report(g.current_profile.id, current_report_id)
        key_words_groups = group_keywords(key_words_obj)
    except Exception as e:
        logger.error(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚ùå –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
        return render_template("errors/error.html", message=f"–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø–æ–ª–æ—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
    
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ------------------------------------")
    logger.info(f"(—Ä–∞–±–æ—Ç–∞ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º) ‚úÖ –î–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏ –µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã. –ó–∞–≥—Ä—É–∂–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É")
    return render_template(
        "working_with_report.html", 
        title=report_data["report_name"],
        report_data=report_data,
        paragraphs_data=paragraphs_data,
        full_name=full_name,
        birthdate=birthdate,
        report_number=report_number,
        key_words_groups=key_words_groups,
    )


# –ú–∞—Ä—à—Ä—É—Ç –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–Ω–∞–ø—à–æ—Ç–æ–≤ (–Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –ø–æ—Ç–æ–º —É–±—Ä–∞—Ç—å –µ–≥–æ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –±–ª—é–ø—Ä–∏–Ω—Ç)
@working_with_reports_bp.route("/snapshots", methods=["GET"])
@auth_required()
def snapshots():
    logger.info(f"(–ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–Ω–∞–ø—à–æ—Ç–æ–≤) ------------------------------------")
    logger.info(f"(–ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–Ω–∞–ø—à–æ—Ç–æ–≤) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–Ω–∞–ø—à–æ—Ç–æ–≤")
    
    user_id = current_user.id
    current_profile = g.current_profile

    date_str = request.args.get("date")
    report_type = request.args.get("report_type")

    snapshots = []
    if date_str and report_type:
        try:
            date_obj = datetime.strptime(date_str, "%Y-%m-%d").date()
            report_type_int = int(report_type)
            snapshots = ReportTextSnapshot.find_by_date_and_type(user_id, date_obj, report_type_int)
        except Exception as e:
            logger.error(f"[report_snapshots] ‚ùå –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–Ω–∞–ø—à–æ—Ç–æ–≤: {e}")

    report_types = ReportType.find_by_profile(current_profile.id)

    return render_template(
        "snapshots.html",
        snapshots=snapshots,
        report_types=report_types
    )



@working_with_reports_bp.route("/snapshots_json", methods=["POST"])
@auth_required()
def snapshots_json():
    logger.info(f"(snapshots_json) ------------------------------------")
    logger.info(f"(snapshots_json) üöÄ –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Å–Ω–∞–ø—à–æ—Ç–æ–≤")
    logger.info(f"(snapshots_json) –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {request.get_json()}")
    try:
        data = request.get_json()
        date_str = data.get("date")
        report_type = int(data.get("report_type"))
        user_id = current_user.id

        date_obj = datetime.strptime(date_str, "%Y-%m-%d").date()
        snapshots = ReportTextSnapshot.find_by_date_and_type(user_id, date_obj, report_type)
        logger.info(f"(snapshots_json) ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(snapshots)} —Å–Ω–∞–ø—à–æ—Ç–æ–≤ –¥–ª—è –¥–∞—Ç—ã {date_str} –∏ —Ç–∏–ø–∞ {report_type}")

        data = render_template("partials/snapshot_results_snippet.html", snapshots=snapshots)
        logger.info(f"(snapshots_json) ‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–Ω–∞–ø—à–æ—Ç–æ–≤ —É—Å–ø–µ—à–Ω–æ –æ—Ç—Ä–µ–Ω–¥–µ—Ä–µ–Ω—ã")
        logger.info(f"(snapshots_json) ------------------------------------")
        return jsonify({"status": "success", "data": data}), 200

    except Exception as e:
        logger.error(f"(snapshots_json) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–Ω–∞–ø—à–æ—Ç–æ–≤: {e}")
        return jsonify({"status": "error", "message": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å–Ω–∞–ø—à–æ—Ç–æ–≤"}), 500
    
    

@working_with_reports_bp.route("/save_modified_sentences", methods=["POST"])
@auth_required()
def save_modified_sentences():
    """
    Processes and saves new or modified sentences to the database.
    Handles splitting of multi-sentence inputs and normalizes valid sentences.
    Keeps track of saved, skipped, and missed sentences.
    """
    
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ------------------------------------")
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        data = request.get_json()
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {data}")

        report_id = int(data.get("report_id"))
        sentences = ensure_list(data.get("sentences"))
        user_id = current_user.id
        report_type_id = Report.get_report_type_id(report_id)
        
        if not sentences or not report_id:
            logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–ª–∏ id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
            return jsonify({"status": "error", "message": "–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–ª–∏ id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞"}), 400
        
        processed_sentences = []  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, 
        #–æ—Ç–ø—Ä–∞–≤–ª—é –∏—Ö –ø–æ—Ç–æ–º –Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤ —Ñ—É–Ω–∫—Ü–∏—é compare_sentences_by_paragraph
        missed_count = 0  # –°—á—ë—Ç—á–∏–∫ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        

        for sentence_data in sentences:
            head_sentence_id = sentence_data.get("head_sentence_id", None)
            paragraph_id = sentence_data.get("paragraph_id")
            nativ_text = sentence_data.get("text")
            sentence_type = sentence_data.get("type")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
            if not paragraph_id or not nativ_text.strip():
                missed_count += 1
                logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –¥–∞–Ω–Ω—ã–µ –±–µ–∑ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç: {sentence_data}")
                continue  
            
            before_split_text = preprocess_sentence(nativ_text)
            
            if not before_split_text.strip():
                missed_count += 1
                continue  
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
            unsplited_sentences, splited_sentences = split_sentences_if_needed(before_split_text)

            if splited_sentences:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª—É—á–∞–∏ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º
                for idx, splited_sentence in enumerate(splited_sentences):
                    if splited_sentence.strip() == "":
                        missed_count += 1
                        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –ø—É—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {splited_sentence}")
                        continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                    if sentence_type == "body":
                        new_sentence_type = "body" if idx == 0 else "tail"
                    else:
                        new_sentence_type = "tail"
                    processed_sentences.append({
                        "paragraph_id": paragraph_id,
                        "head_sentence_id": head_sentence_id,
                        "sentence_type": new_sentence_type,
                        "text": splited_sentence.strip()
                    })
            else:
                for unsplited_sentence in unsplited_sentences:
                    if unsplited_sentence.strip() == "":
                        missed_count += 1
                        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é –ø—É—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: {unsplited_sentence}")
                        continue
                    processed_sentences.append({
                        "paragraph_id": paragraph_id,
                        "head_sentence_id": head_sentence_id,
                        "sentence_type": "body" if sentence_type == "body" else "tail",
                        "text": unsplited_sentence.strip()
                    })

        # –¢–µ–ø–µ—Ä—å —Ä–∞–±–æ—Ç–∞–µ–º —Å —É–∂–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –≤ processed_sentences
        
        # –°–Ω–∞—á–∞–ª–∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏—Ö —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        comparsion_result = compare_sentences_by_paragraph(
                                                        processed_sentences,
                                                        report_id)
        
        new_sentences = comparsion_result["unique"]
        duplicates = comparsion_result["duplicates"]
        errors_count = comparsion_result["errors_count"]
        
        missed_count = 0  # –°—á—ë—Ç—á–∏–∫ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        saved_count = 0  # –°—á—ë—Ç—á–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        saved_sentences = []  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –æ—Ç—á–µ—Ç

        for sentence in new_sentences:
            processed_paragraph_id = sentence["paragraph_id"]
            new_sentence_text = clean_and_normalize_text(sentence["text"])
            sentence_type = sentence["sentence_type"]
            related_id = processed_paragraph_id if sentence_type == "tail" else head_sentence_id
            try:
                if sentence_type == "tail":
                   new_sentence, sent_group = TailSentence.create(
                        sentence=new_sentence_text,
                        related_id=related_id,
                        user_id=user_id,
                        report_type_id=report_type_id,
                        comment="Added automatically"
                    )
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –≤ –∫–∞—á–µ—Å—Ç–≤–µ body_sentence 
                # –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –≥–ª–∞–≤–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                else:
                    if sentence["head_sentence_id"]:
                        new_sentence, sent_group = BodySentence.create(
                        sentence=new_sentence_text,
                        related_id=related_id,
                        user_id=user_id,
                        report_type_id=report_type_id,
                        comment="Added automatically",
                        )
                    else:
                        logger.warning(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω head_sentence_id –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {new_sentence_text}. –ü—Ä–æ–ø—É—Å–∫–∞—é –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ")
                        missed_count += 1   
                        continue
                saved_count += 1
                saved_sentences.append({"id": new_sentence.id, "related_id": related_id, "sentence_type": sentence_type, "text": new_sentence_text})
            except Exception as e:
                logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ùå –ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è ({new_sentence_text}) –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}. –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ —Å—á—ë—Ç—á–∏–∫")
                missed_count += 1

        sentences_adding_report = {
            "message": f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {len(processed_sentences)}.",
            "saved_count": saved_count,
            "skipped_count": len(processed_sentences) - saved_count,
            "missed_count": missed_count,
            "duplicates_count": len(duplicates),
            "errors_count": errors_count,
            "saved_sentences": saved_sentences,
            "duplicates": duplicates
        }

        rendered_html = render_template(
            "sentences_adding_report_snippet.html", 
            **sentences_adding_report)
        
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(processed_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.")
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ------------------------------------")
        return jsonify({
            "status": "success",
            "message": f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(processed_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.",
            "html": rendered_html
        }), 200

    except Exception as e:
        logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) ‚ùå –ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")
        return jsonify({"status": "error", "message": f"–ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"}), 500



@working_with_reports_bp.route("/export_to_word", methods=["POST"])
@auth_required()
def export_to_word():
    try:
        data = request.get_json()
        if data is None:
                return jsonify({"status": "error", "message": "No JSON data received"}), 400
        text = data.get("text")
        name = data.get("name") or "noname"
        subtype = data.get("subtype")
        report_type = data.get("report_type")
        birthdate = data.get("birthdate")
        reportnumber = data.get("reportnumber")
        scanParam = data.get("scanParam")
        side = data.get("side")

        if not text or not name or not subtype:
            return jsonify({"status": "error", "message": "Missing required information."}), 400
    except Exception as e:
        return jsonify({"status": "error", "message": f"Error processing request: {e}"}), 500

    try:
        file_path = save_to_word(text, name, subtype, report_type, birthdate, reportnumber, scanParam, side=side)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª
        if not os.path.exists(file_path):
            return jsonify({"status": "error", "message": "File not found"}), 500
        
        return send_file(file_path, as_attachment=True)
    except Exception as e:
        return jsonify({"status": "error", "message": f"Failed to export to Word: {e}"}), 500




@working_with_reports_bp.route("/save_report_snapshot", methods=["POST"])
@auth_required()
def save_report_snapshot():
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ------------------------------------")
    logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
    try:
        data = request.get_json()
        if not data:
            logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON")
            return jsonify({"status": "error", "message": "No JSON data received"}), 400
        report_id = data.get("report_id")
        text = data.get("text")
        if not report_id or not text:
            logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç id –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞ –∫–æ–ø–∏–∏")
            return jsonify({"status": "error", "message": "Missing required information."}), 400
        
        user_id = current_user.id
        
    except Exception as e:
        logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return jsonify({"status": "error", "message": f"Error processing request: {e}"}), 500

    try:
        ReportTextSnapshot.create(report_id, user_id, text)
        logger.info(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚úÖ –ö–æ–ø–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        return jsonify({"status": "success", "message": "Report snapshot saved"}), 200
    except Exception as e:
        logger.error(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–ø–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞) ‚ùå –ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–ø–∏—é –ø—Ä–æ—Ç–æ–∫–æ–ª–∞: {e}")
        return jsonify({"status": "error", "message": f"Failed to save report snapshot: {e}"}), 500
    


@working_with_reports_bp.route("/train_sentence_boundary", methods=["POST"])
@auth_required()
def train_sentence_boundary():
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Ä–∞–∑–º–µ—á–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ–≥–æ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è SpaCy.
    """
    data = request.get_json()
    text = data.get("text")
    sent_starts = data.get("sent_starts")
    if not text or not sent_starts:
        return jsonify({"status": "error", "message": "Missing text or sent_starts"}), 400
    
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ jsonl
        training_example = {
            "text": text,
            "sent_starts": sent_starts
        }

        file_path = os.path.join("spacy_training_data", "sent_boundary.jsonl")
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(training_example, ensure_ascii=False) + "\n")
        
        return jsonify({"status": "success", "message": "Example saved"}), 200
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500
    
    
    
    
@working_with_reports_bp.route("/get_spacy_tokens", methods=["POST"])
@auth_required()
def get_spacy_tokens():
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ç SpaCy —Å is_sent_start.
    """
    
    language = current_app.config.get("PROFILE_SETTINGS", {}).get("APP_LANGUAGE", "ru")

    data = request.get_json()
    text = data.get("text", "").strip()
    if not text:
        return jsonify({"status": "error", "message": "–¢–µ–∫—Å—Ç –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω"}), 400

    try:
        nlp = SpacyModel.get_instance(language)
        doc = nlp(text)
        tokens = [
            {
                "text": token.text,
                "idx": token.idx,
                "is_sent_start": token.is_sent_start
            }
            for token in doc
        ]
        return jsonify({"status": "success", "tokens": tokens}), 200

    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500
    
    
    
    
# editing_report.py
@working_with_reports_bp.route("/increase_sentence_weight", methods=["POST"])
@auth_required()
def increase_sentence_weight():
    logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ------------------------------------")
    logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
    data = request.get_json()
    sentence_id = data.get("sentence_id")
    group_id = data.get("group_id")
    sentence_type = data.get("sentence_type")
    
    logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {data}")

    if not sentence_id or not group_id or sentence_type not in ["body", "tail"]:
        logger.error(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
        return jsonify({"status": "error", "message": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö"}), 400

    try:
        if sentence_type == "body":
            BodySentence.increase_weight(sentence_id, group_id)
        else:
            TailSentence.increase_weight(sentence_id, group_id)
        logger.info(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ‚úÖ –í–µ—Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ —É–≤–µ–ª–∏—á–µ–Ω")
        return jsonify({"status": "success", "message": "–í–µ—Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —É–≤–µ–ª–∏—á–µ–Ω"}), 200
    except Exception as e:
        logger.error(f"(–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤–µ—Å–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤–µ—Å–∞: {e}")
        return jsonify({"status": "error", "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤–µ—Å–∞: {e}"}), 500